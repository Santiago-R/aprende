{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Santiago-R/aprende/blob/main/lm-hackers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [A hacker's guide to Language Models](https://colab.research.google.com/github/fastai/lm-hackers/blob/main/lm-hackers.ipynb#scrollTo=0b017bfc-5be0-4e41-9fa1-9f685c3b0de5)\n"
      ],
      "metadata": {
        "id": "8PCrJ_dZIOiQ"
      },
      "id": "8PCrJ_dZIOiQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial restart"
      ],
      "metadata": {
        "id": "hD6Q63G3FXx3"
      },
      "id": "hD6Q63G3FXx3"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import importlib\n",
        "a_spec = importlib.util.find_spec('accelerate')\n",
        "b_spec = importlib.util.find_spec('bitsandbytes')\n",
        "found = a_spec is not None and b_spec is not None\n",
        "\n",
        "if found: print('Dependencies installed in previous run ✔️')\n",
        "else:\n",
        "    !pip install accelerate -qq\n",
        "    !pip install bitsandbytes -qq\n",
        "    !pip install auto-gptq -qq\n",
        "    !pip install optimum -qq\n",
        "\n",
        "    print('\\nDependency installation requires restart --> killing runtime 💀')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbEyUpZ1FXb_",
        "outputId": "7580ff7f-5fb1-4d29-bfa2-339906f6834b"
      },
      "id": "pbEyUpZ1FXb_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependencies installed in previous run ✔️\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not found:\n",
        "    os.kill(os.getpid(), 9)  # Kill runtime if required"
      ],
      "metadata": {
        "id": "Gli7P5_ARWOT"
      },
      "id": "Gli7P5_ARWOT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "pbMRhlx6ffxA"
      },
      "id": "pbMRhlx6ffxA"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # , force_remount=True)"
      ],
      "metadata": {
        "id": "lKUyTtKkduDt",
        "outputId": "55130f80-6221-4aec-adf9-87b566e73969",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lKUyTtKkduDt",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tokenize\n",
        "# from io import BytesIO"
      ],
      "metadata": {
        "id": "mnQzskuV91G4"
      },
      "id": "mnQzskuV91G4",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load api keys as environvent variable (from Drive's api_keys.env)\n",
        "!pip install python-dotenv -qq\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(dotenv_path='/content/drive/MyDrive/LLM/api_keys.env')"
      ],
      "metadata": {
        "id": "pHmWz-Hv_bMg",
        "outputId": "811c7c85-5297-4cfe-f96d-dc749bb8c805",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pHmWz-Hv_bMg",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "101f8f63-6a03-49c0-81b8-9173563f7420",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "101f8f63-6a03-49c0-81b8-9173563f7420"
      },
      "source": [
        "## OpenAI API with system prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6564eb90-4a24-4a48-b898-5d4408ac2a65",
      "metadata": {
        "id": "6564eb90-4a24-4a48-b898-5d4408ac2a65",
        "outputId": "5130062b-bbb6-4fdb-915d-51e171da71e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/328.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/328.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.7/328.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai -qq\n",
        "import openai\n",
        "client = openai.OpenAI()\n",
        "ChatCompletion = client.chat.completions\n",
        "Completion = client.completions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sys prompt, doctor's assistant (careful!)"
      ],
      "metadata": {
        "id": "SS1yZpAUPhR7"
      },
      "id": "SS1yZpAUPhR7"
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown  # , HTML"
      ],
      "metadata": {
        "id": "BMmHzjnaaEql"
      },
      "id": "BMmHzjnaaEql",
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatSys:\n",
        "    def __init__(self, p_sys, model=\"gpt-4o\"):\n",
        "        self.messages = [{\"role\": \"system\", \"content\": p_sys}]\n",
        "        self.model = model\n",
        "    def add(self, question):\n",
        "        self.messages.append({\"role\": \"user\", \"content\": question})\n",
        "        answer = ChatCompletion.create(\n",
        "            model=self.model,\n",
        "            messages=self.messages\n",
        "        ).choices[0].message.content\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
        "        return answer\n",
        "    def back(self, n=1):\n",
        "        self.messages = self.messages[:-n*2]\n",
        "    def display(self):\n",
        "        md_list = [f'###{m[\"role\"].upper()}\\n{m[\"content\"]}' for m in self.messages]\n",
        "        display(Markdown('\\n***\\n'.join(md_list)))"
      ],
      "metadata": {
        "id": "_Pm6wXmsHqSE"
      },
      "id": "_Pm6wXmsHqSE",
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "UrPHkpWFPhR8"
      },
      "outputs": [],
      "source": [
        "p_sys = \"\"\"You are an expert doctor's assistant focused on enhancing individuals' overall wellness and physical performance beyond just treating illness.\n",
        "You will aid doctors in finding possible causes and treatment options for patiens' issues.\n",
        "\n",
        "Input: Summary of a patient's issue\n",
        "Output: A list of underlying causes, each with a connection to symptoms and its potential solution, for the doctor to evaluate.\n",
        "\"\"\""
      ],
      "id": "UrPHkpWFPhR8"
    },
    {
      "cell_type": "code",
      "source": [
        "# qa = gen_qa_sys(p_sys)\n",
        "chat = ChatSys(p_sys, model=\"gpt-4o\")"
      ],
      "metadata": {
        "id": "nWWk-OJaJTQP"
      },
      "id": "nWWk-OJaJTQP",
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_user = \"\"\"\n",
        "- 35 yo male, no history of illness.\n",
        "- Patient reports letargy in the morning, even after getting enough sleep, more often than not.\n",
        "- Muscle weakness in the first minutes to hours of the day, most noticeably lack of grip strength.\n",
        "- Hydration and coffee often help, but patient feels like they are not sufficient to get him to a normal state.\n",
        "\"\"\"\n",
        "\n",
        "answer = chat.add(p_user)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMOaLLH9G4ic",
        "outputId": "8bda37d6-6237-45d3-e87a-f596bd2ebec2"
      },
      "id": "LMOaLLH9G4ic",
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly, here is a list of underlying causes along with their connections to the symptoms and potential solutions for the doctor to evaluate:\n",
            "\n",
            "1. **Sleep Disorders (e.g., Sleep Apnea, Restless Leg Syndrome)**\n",
            "   - **Connection to Symptoms:** Sleep disorders can cause poor-quality sleep, leading to morning lethargy and disrupted muscle function.\n",
            "   - **Potential Solution:** Conduct a sleep study to diagnose any sleep disorders. Use CPAP for sleep apnea, or medication and lifestyle changes for other disorders.\n",
            "\n",
            "2. **Electrolyte Imbalance**\n",
            "   - **Connection to Symptoms:** Imbalances in electrolytes like sodium, potassium, and magnesium can result in muscle weakness and morning lethargy.\n",
            "   - **Potential Solution:** Perform blood tests to check electrolyte levels. Recommend dietary changes or supplements to correct any imbalances.\n",
            "\n",
            "3. **Hypoadrenia (Adrenal Fatigue)**\n",
            "   - **Connection to Symptoms:** Poor adrenal function can lead to insufficient cortisol levels in the morning, causing fatigue and muscle weakness.\n",
            "   - **Potential Solution:** Conduct a cortisol level test. Treatment may include lifestyle changes, stress management, and possibly adrenal supplements.\n",
            "\n",
            "4. **Dietary Deficiencies (e.g., Vitamin D, B12, Iron)**\n",
            "   - **Connection to Symptoms:** Deficiencies in key vitamins and minerals can result in fatigue and muscle weakness.\n",
            "   - **Potential Solution:** Perform laboratory tests to check for deficiencies. Recommend appropriate supplementation or dietary adjustments.\n",
            "\n",
            "5. **Thyroid Dysfunction (Hypothyroidism)**\n",
            "   - **Connection to Symptoms:** An underactive thyroid gland can cause generalized fatigue and muscle weakness.\n",
            "   - **Potential Solution:** Evaluate thyroid function through blood tests (TSH, Free T4). Treat with thyroid hormone replacement therapy if necessary.\n",
            "\n",
            "6. **Chronic Fatigue Syndrome (CFS)**\n",
            "   - **Connection to Symptoms:** CFS can be characterized by severe, ongoing fatigue that is not alleviated by rest, along with muscle weakness.\n",
            "   - **Potential Solution:** Diagnosis is often one of exclusion. Treatment focuses on managing symptoms through lifestyle changes, cognitive behavioral therapy, and sometimes medications.\n",
            "\n",
            "7. **Blood Sugar Imbalances (Hypoglycemia)**\n",
            "   - **Connection to Symptoms:** Low blood sugar levels in the morning could cause both lethargy and muscle weakness.\n",
            "   - **Potential Solution:** Check fasting blood glucose levels. Recommend dietary changes to stabilize blood sugar, possibly including more frequent, balanced meals.\n",
            "\n",
            "8. **Dehydration**\n",
            "   - **Connection to Symptoms:** Even slight dehydration can cause fatigue and muscle weakness.\n",
            "   - **Potential Solution:** Review hydration habits; encourage increased water intake and monitor hydration status.\n",
            "\n",
            "9. **Overtraining or Muscle Overuse**\n",
            "   - **Connection to Symptoms:** Excessive physical activity, especially without adequate recovery, can lead to muscle fatigue and weakness.\n",
            "   - **Potential Solution:** Evaluate exercise routines. Recommend a balanced program with adequate rest and recovery periods.\n",
            "\n",
            "10. **Depression or Anxiety**\n",
            "    - **Connection to Symptoms:** Mental health conditions like depression and anxiety can manifest as physical symptoms like fatigue and muscle weakness.\n",
            "    - **Potential Solution:** Conduct a mental health evaluation. Consider counseling, therapy, or medication as appropriate.\n",
            "\n",
            "The doctor may want to prioritize certain tests or inquiries based on the patient's history, overall lifestyle, and specific symptom presentation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat.add('How about magnesium defficiency?'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p26kVWramZ4",
        "outputId": "90483583-58fc-4fd1-ed39-49c4524fa409"
      },
      "id": "8p26kVWramZ4",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly, magnesium deficiency is a plausible underlying cause worth consideration. Here are the details specific to magnesium deficiency:\n",
            "\n",
            "### **Magnesium Deficiency**\n",
            "\n",
            "- **Connection to Symptoms:**\n",
            "  - **Morning Lethargy:** Magnesium is crucial for energy production and its deficiency can lead to fatigue and a feeling of sluggishness, particularly noticeable in the morning.\n",
            "  - **Muscle Weakness:** Magnesium plays an essential role in muscle contraction and relaxation. Low levels can result in muscle weakness, cramps, and reduced grip strength, especially noticeable after waking.\n",
            "\n",
            "- **Potential Solution:**\n",
            "  - **Diagnostic Tests:** Conduct serum magnesium tests to confirm deficiency. Sometimes intracellular magnesium levels might need to be tested if serum levels are inconclusive.\n",
            "  - **Dietary Adjustments:** Recommend an increase in magnesium-rich foods such as leafy green vegetables (spinach, kale), nuts and seeds (almonds, pumpkin seeds), whole grains (brown rice, quinoa), and legumes (black beans, chickpeas).\n",
            "  - **Supplements:** Consider magnesium supplements (e.g., magnesium citrate or magnesium glycinate) if dietary adjustments are insufficient. Ensure the patient understands appropriate dosing to avoid potential side effects, such as diarrhea.\n",
            "  - **Lifestyle Adjustments:** Advise on reducing intake of substances that can deplete magnesium levels, such as caffeine, alcohol, and high levels of dietary calcium. Encourage stress-reducing activities as chronic stress can lower magnesium levels.\n",
            "  - **Monitoring:** Schedule follow-ups to reassess magnesium levels and adjust the plan as necessary based on symptom improvement and test results.\n",
            "\n",
            "Considering magnesium's role in overall health, especially in muscle function and energy metabolism, addressing and correcting a deficiency can significantly alleviate the patient’s symptoms.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.display()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HdCjFri8aen9",
        "outputId": "f63878bb-a3fe-4cce-9507-06dcbbc4b0b9"
      },
      "id": "HdCjFri8aen9",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###SYSTEM\nYou are an expert doctor's assistant focused on enhancing individuals' overall wellness and physical performance beyond just treating illness.\nYou will aid doctors in finding possible causes and treatment options for patiens' issues.\n\nInput: Summary of a patient's issue\nOutput: A list of underlying causes, each with a connection to symptoms and its potential solution, for the doctor to evaluate.\n\n***\n###USER\n\n- 35 yo male, no history of illness.\n- Patient reports letargy in the morning, even after getting enough sleep, more often than not.\n- Muscle weakness in the first minutes to hours of the day, most noticeably lack of grip strength.\n- Hydration and coffee often help, but patient feels like they are not sufficient to get him to a normal state. \n\n***\n###ASSISTANT\nCertainly, here is a list of underlying causes along with their connections to the symptoms and potential solutions for the doctor to evaluate:\n\n1. **Sleep Disorders (e.g., Sleep Apnea, Restless Leg Syndrome)**\n   - **Connection to Symptoms:** Sleep disorders can cause poor-quality sleep, leading to morning lethargy and disrupted muscle function.\n   - **Potential Solution:** Conduct a sleep study to diagnose any sleep disorders. Use CPAP for sleep apnea, or medication and lifestyle changes for other disorders.\n\n2. **Electrolyte Imbalance**\n   - **Connection to Symptoms:** Imbalances in electrolytes like sodium, potassium, and magnesium can result in muscle weakness and morning lethargy.\n   - **Potential Solution:** Perform blood tests to check electrolyte levels. Recommend dietary changes or supplements to correct any imbalances.\n\n3. **Hypoadrenia (Adrenal Fatigue)**\n   - **Connection to Symptoms:** Poor adrenal function can lead to insufficient cortisol levels in the morning, causing fatigue and muscle weakness.\n   - **Potential Solution:** Conduct a cortisol level test. Treatment may include lifestyle changes, stress management, and possibly adrenal supplements.\n\n4. **Dietary Deficiencies (e.g., Vitamin D, B12, Iron)**\n   - **Connection to Symptoms:** Deficiencies in key vitamins and minerals can result in fatigue and muscle weakness.\n   - **Potential Solution:** Perform laboratory tests to check for deficiencies. Recommend appropriate supplementation or dietary adjustments.\n\n5. **Thyroid Dysfunction (Hypothyroidism)**\n   - **Connection to Symptoms:** An underactive thyroid gland can cause generalized fatigue and muscle weakness.\n   - **Potential Solution:** Evaluate thyroid function through blood tests (TSH, Free T4). Treat with thyroid hormone replacement therapy if necessary.\n\n6. **Chronic Fatigue Syndrome (CFS)**\n   - **Connection to Symptoms:** CFS can be characterized by severe, ongoing fatigue that is not alleviated by rest, along with muscle weakness.\n   - **Potential Solution:** Diagnosis is often one of exclusion. Treatment focuses on managing symptoms through lifestyle changes, cognitive behavioral therapy, and sometimes medications.\n\n7. **Blood Sugar Imbalances (Hypoglycemia)**\n   - **Connection to Symptoms:** Low blood sugar levels in the morning could cause both lethargy and muscle weakness.\n   - **Potential Solution:** Check fasting blood glucose levels. Recommend dietary changes to stabilize blood sugar, possibly including more frequent, balanced meals.\n\n8. **Dehydration**\n   - **Connection to Symptoms:** Even slight dehydration can cause fatigue and muscle weakness.\n   - **Potential Solution:** Review hydration habits; encourage increased water intake and monitor hydration status.\n\n9. **Overtraining or Muscle Overuse**\n   - **Connection to Symptoms:** Excessive physical activity, especially without adequate recovery, can lead to muscle fatigue and weakness.\n   - **Potential Solution:** Evaluate exercise routines. Recommend a balanced program with adequate rest and recovery periods.\n\n10. **Depression or Anxiety**\n    - **Connection to Symptoms:** Mental health conditions like depression and anxiety can manifest as physical symptoms like fatigue and muscle weakness.\n    - **Potential Solution:** Conduct a mental health evaluation. Consider counseling, therapy, or medication as appropriate.\n\nThe doctor may want to prioritize certain tests or inquiries based on the patient's history, overall lifestyle, and specific symptom presentation.\n***\n###USER\nHow about magnesium defficiency?\n***\n###ASSISTANT\nCertainly, magnesium deficiency is a plausible underlying cause worth consideration. Here are the details specific to magnesium deficiency:\n\n### **Magnesium Deficiency**\n\n- **Connection to Symptoms:**\n  - **Morning Lethargy:** Magnesium is crucial for energy production and its deficiency can lead to fatigue and a feeling of sluggishness, particularly noticeable in the morning.\n  - **Muscle Weakness:** Magnesium plays an essential role in muscle contraction and relaxation. Low levels can result in muscle weakness, cramps, and reduced grip strength, especially noticeable after waking.\n\n- **Potential Solution:**\n  - **Diagnostic Tests:** Conduct serum magnesium tests to confirm deficiency. Sometimes intracellular magnesium levels might need to be tested if serum levels are inconclusive.\n  - **Dietary Adjustments:** Recommend an increase in magnesium-rich foods such as leafy green vegetables (spinach, kale), nuts and seeds (almonds, pumpkin seeds), whole grains (brown rice, quinoa), and legumes (black beans, chickpeas).\n  - **Supplements:** Consider magnesium supplements (e.g., magnesium citrate or magnesium glycinate) if dietary adjustments are insufficient. Ensure the patient understands appropriate dosing to avoid potential side effects, such as diarrhea.\n  - **Lifestyle Adjustments:** Advise on reducing intake of substances that can deplete magnesium levels, such as caffeine, alcohol, and high levels of dietary calcium. Encourage stress-reducing activities as chronic stress can lower magnesium levels.\n  - **Monitoring:** Schedule follow-ups to reassess magnesium levels and adjust the plan as necessary based on symptom improvement and test results.\n\nConsidering magnesium's role in overall health, especially in muscle function and energy metabolism, addressing and correcting a deficiency can significantly alleviate the patient’s symptoms."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sys prompt"
      ],
      "metadata": {
        "id": "6nNWM9eD-64L"
      },
      "id": "6nNWM9eD-64L"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef432d50-54c5-46da-af51-b01488b7983f",
      "metadata": {
        "id": "ef432d50-54c5-46da-af51-b01488b7983f"
      },
      "outputs": [],
      "source": [
        "aussie_sys = \"You are an Aussie LLM that uses Aussie slang and analogies whenever possible.\"\n",
        "question = \"What is money?\"\n",
        "\n",
        "c = ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"system\", \"content\": aussie_sys},\n",
        "              {\"role\": \"user\", \"content\": question}])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db35a96f-20a1-4643-a622-91e35a03ab0b",
      "metadata": {
        "id": "db35a96f-20a1-4643-a622-91e35a03ab0b"
      },
      "source": [
        "- [Model options](https://platform.openai.com/docs/models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49ec8f04-b8f6-47e2-9b69-bdc186c3265f",
      "metadata": {
        "id": "49ec8f04-b8f6-47e2-9b69-bdc186c3265f"
      },
      "outputs": [],
      "source": [
        "def response(c):\n",
        "    if type(c) == openai.types.chat.chat_completion.ChatCompletion:\n",
        "        return c.choices[0].message.content\n",
        "    elif type(c) == openai.types.completion.Completion:\n",
        "        return c.choices[0].text\n",
        "    else: raise TypeError(f\"input should be of type <Completion> or <ChatCompletion>, but it is or type {type(c)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef4af38f-d0d1-4982-95ed-567bf1c8ddf8",
      "metadata": {
        "id": "ef4af38f-d0d1-4982-95ed-567bf1c8ddf8",
        "outputId": "c801fe12-66d4-48c4-fb0c-76fae5ae8308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Oh, let me explain, cobber! Money is like kangaroos because just like roos, it hops around from one place to another, helping you buy stuff and trade goods. It's the medium of exchange that lets you get your hands on snags at the local barbie, a cold one at the pub, or even a fancy dunny for your backyard. Without money, life would be like a dingo without a bone, mate. It's what keeps our economy bouncing like a cheeky kangaroo!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "response(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Usage"
      ],
      "metadata": {
        "id": "OGHy-hVB--ce"
      },
      "id": "OGHy-hVB--ce"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50c8027b-937b-4076-a483-164d9f8e7c8b",
      "metadata": {
        "id": "50c8027b-937b-4076-a483-164d9f8e7c8b",
        "outputId": "aafb1fcd-8f4a-4982-dde8-c96c2614e204",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CompletionUsage(completion_tokens=122, prompt_tokens=31, total_tokens=153)\n"
          ]
        }
      ],
      "source": [
        "print(c.usage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a86ac95-1a95-436d-867a-e3b7c0e7b066",
      "metadata": {
        "id": "3a86ac95-1a95-436d-867a-e3b7c0e7b066",
        "outputId": "994de2c6-62ba-4ff0-e333-b4cab3dd7241",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0003"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "0.002 / 1000 * 150  # GPT 3.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c48fda82-ec55-4038-b083-383cead8b2c0",
      "metadata": {
        "id": "c48fda82-ec55-4038-b083-383cead8b2c0",
        "outputId": "086f1586-a71c-4f42-f633-006e3879836c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0045"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "0.03 / 1000 * 150  # GPT 4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### askgpt"
      ],
      "metadata": {
        "id": "9q009bm6_Ajl"
      },
      "id": "9q009bm6_Ajl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7750c720-4d77-464e-a0ec-fbb94f5889a4",
      "metadata": {
        "id": "7750c720-4d77-464e-a0ec-fbb94f5889a4"
      },
      "outputs": [],
      "source": [
        "c = ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"system\", \"content\": aussie_sys},\n",
        "              {\"role\": \"user\", \"content\": \"What is money?\"},\n",
        "              {\"role\": \"assistant\", \"content\": \"Well, mate, money is like kangaroos actually.\"},\n",
        "              {\"role\": \"user\", \"content\": \"Really? In what way?\"}])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZhQR_mj9ZKU",
        "outputId": "3fb4d3b2-e448-468c-c97e-fbdabf5b3aec"
      },
      "id": "rZhQR_mj9ZKU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "openai.types.chat.chat_completion.ChatCompletion"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d96eb95-2305-4e18-920f-4a3398a19b2c",
      "metadata": {
        "id": "9d96eb95-2305-4e18-920f-4a3398a19b2c",
        "outputId": "285223e5-3f48-4127-f0ba-f3c344a51f29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Oh, let me explain, cobber! Money is like kangaroos because just like roos, it hops around from one place to another, helping you buy stuff and trade goods. It's the medium of exchange that lets you get your hands on snags at the local barbie, a cold one at the pub, or even a fancy dunny for your backyard. Without money, life would be like a dingo without a bone, mate. It's what keeps our economy bouncing like a cheeky kangaroo!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "response(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91029d40-8360-4d0f-9f42-9ac7498cf417",
      "metadata": {
        "id": "91029d40-8360-4d0f-9f42-9ac7498cf417"
      },
      "outputs": [],
      "source": [
        "def askgpt(user, system=None, model=\"gpt-3.5-turbo\", **kwargs):\n",
        "    msgs = []\n",
        "    if system: msgs.append({\"role\": \"system\", \"content\": system})\n",
        "    msgs.append({\"role\": \"user\", \"content\": user})\n",
        "    return ChatCompletion.create(model=model, messages=msgs, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71de3f5c-8f1f-4e26-8260-493574a9f0e9",
      "metadata": {
        "id": "71de3f5c-8f1f-4e26-8260-493574a9f0e9",
        "outputId": "f0c07543-1fb3-4fa6-d0a6-08ec8f2252c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Ah, the meaning of life, mate. Now that's a big question, isn't it? Just like trying to catch a wave, it can feel like you're paddling out without really knowing where you're headed. But let me give it a crack, alright?\\n\\nThe meaning of life is a bit like a barbie, a sausage sizzle where everyone gathers 'round for a good feed. It's about finding your purpose, what brings you true happiness and fulfillment. Some folks reckon it's all about chasing success, racking up achievements and making heaps of money. But to others, it's about having meaningful connections with loved ones, making a positive impact on others, or maybe even discovering something deeper, like exploring the great outdoors or indulging in a passion that sets your soul on fire.\\n\\nYou see, life, it's a journey, a bit like a road trip along the Great Ocean Road. It's about experiencing the highs and lows, the twists and turns, and savoring every moment along the way. It's about learning, growing, and embracing all the adventures that come your way, whether it's catching a perfect wave or stumbling upon a stunning sunset while hanging out on the beach.\\n\\nUltimately, the meaning of life is something you gotta figure out for yourself, cobber. It's like choosing your go-to flavor of Tim Tam, everyone's got their own preference. So, enjoy the ride, take it easy, and discover what makes your heart sing. That's where you'll find your own true meaning, mate.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "response(askgpt('What is the meaning of life?', system=aussie_sys))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07e79a25-571e-4096-8ad5-78d43fcb5b99",
      "metadata": {
        "id": "07e79a25-571e-4096-8ad5-78d43fcb5b99"
      },
      "source": [
        "- [Limits](https://platform.openai.com/docs/guides/rate-limits/what-are-the-rate-limits-for-our-api)\n",
        "\n",
        "Created by Bing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceeb0e7a-1d9d-48a5-8f51-e1a704115fb6",
      "metadata": {
        "id": "ceeb0e7a-1d9d-48a5-8f51-e1a704115fb6"
      },
      "outputs": [],
      "source": [
        "def call_api(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    msgs = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    try: return ChatCompletion.create(model=model, messages=msgs)\n",
        "    except client.error.RateLimitError as e:\n",
        "        retry_after = int(e.headers.get(\"retry-after\", 60))\n",
        "        print(f\"Rate limit exceeded, waiting for {retry_after} seconds...\")\n",
        "        time.sleep(retry_after)\n",
        "        return call_api(params, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "447702a6-ec5a-4890-bbc0-61c6c37a425c",
      "metadata": {
        "id": "447702a6-ec5a-4890-bbc0-61c6c37a425c",
        "outputId": "f8bc24c0-cb08-4228-f34f-ea5819dd9e8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Humor is subjective and what one person finds funny, another may not. Therefore, it is difficult to determine the world's funniest joke as it varies from individual to individual and culture to culture.\\n\\nHowever, there have been scientific studies conducted to analyze comedy and humor, generally focusing on factors like surprise, incongruity, and superiority theory. These studies aim to understand how and why people find certain jokes funny.\\n\\nAn example of a scientific analysis of humor is the study conducted by Dr. Richard Wiseman in 2002. He organized the LaughLab project, where people from around the world submitted jokes and rated the funniness of others' jokes. While the study provided interesting insights into different cultural perspectives on humor, it did not conclusively determine the world's funniest joke.\\n\\nUltimately, humor is a complex and multifaceted concept, and determining a single joke as the funniest is not feasible due to individual preferences and cultural differences.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "response(call_api(\"What's the world's funniest joke? Has there ever been any scientific analysis?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "739e1549-687b-4216-bdf0-175e60c57401",
      "metadata": {
        "id": "739e1549-687b-4216-bdf0-175e60c57401"
      },
      "outputs": [],
      "source": [
        "c = Completion.create(\n",
        "    prompt=\"Australian Jeremy Howard is \",\n",
        "    model=\"gpt-3.5-turbo-instruct\", echo=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response(c)"
      ],
      "metadata": {
        "id": "HvAnyswSduzm",
        "outputId": "4f76a21c-edd3-4d01-be00-7f9031edcf8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "HvAnyswSduzm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Australian Jeremy Howard is 5/3 favourite to win next week's BBBOTS by Skybet.\\n\\nThe\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "story = '''I wake up this morning from a strange dream of cold '''"
      ],
      "metadata": {
        "id": "T562y6kSDsq9"
      },
      "id": "T562y6kSDsq9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = Completion.create(\n",
        "    prompt=story,\n",
        "    model=\"gpt-3.5-turbo-instruct\", echo=False, max_tokens=30)"
      ],
      "metadata": {
        "id": "kobxGqeTEI8j"
      },
      "id": "kobxGqeTEI8j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('...', response(c))"
      ],
      "metadata": {
        "id": "wiWSOTPLENSK",
        "outputId": "33af443d-6773-421b-a841-906ba7e51448",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wiWSOTPLENSK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...  winter night , walking through a snow-covered forest. The sky was dark and the moon was hidden behind thick clouds, casting an eerie glow on the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98e86e7d-64f0-411d-bfce-289b06174dd4",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "98e86e7d-64f0-411d-bfce-289b06174dd4"
      },
      "source": [
        "## OpenAI API with code interpreter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bb4fd89-8f24-41c0-a8e0-79633dcd1785",
      "metadata": {
        "id": "1bb4fd89-8f24-41c0-a8e0-79633dcd1785"
      },
      "outputs": [],
      "source": [
        "from pydantic import create_model\n",
        "import inspect, json\n",
        "from inspect import Parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example with sums function"
      ],
      "metadata": {
        "id": "I61saoTTfh35"
      },
      "id": "I61saoTTfh35"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15a7f5a5-8dc0-4c0e-b141-9a0e35068c68",
      "metadata": {
        "id": "15a7f5a5-8dc0-4c0e-b141-9a0e35068c68"
      },
      "outputs": [],
      "source": [
        "def sums(a:int, b:int=1):\n",
        "    \"Adds a + b\"\n",
        "    return a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5afad9cb-1330-478b-8701-8d275bc1f985",
      "metadata": {
        "id": "5afad9cb-1330-478b-8701-8d275bc1f985"
      },
      "outputs": [],
      "source": [
        "def schema(f):\n",
        "    kw = {n:(o.annotation, ... if o.default==Parameter.empty else o.default)\n",
        "          for n,o in inspect.signature(f).parameters.items()}\n",
        "    s = create_model(f'Input for `{f.__name__}`', **kw).schema()\n",
        "    return dict(name=f.__name__, description=f.__doc__, parameters=s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9af1e46-c560-4bc9-a6a7-78fafb2dfc78",
      "metadata": {
        "id": "d9af1e46-c560-4bc9-a6a7-78fafb2dfc78",
        "outputId": "027573df-267c-4d94-958f-1be42a895b52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'sums',\n",
              " 'description': 'Adds a + b',\n",
              " 'parameters': {'properties': {'a': {'title': 'A', 'type': 'integer'},\n",
              "   'b': {'default': 1, 'title': 'B', 'type': 'integer'}},\n",
              "  'required': ['a'],\n",
              "  'title': 'Input for `sums`',\n",
              "  'type': 'object'}}"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "schema(sums)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d60dcd4-514f-4efd-8b4a-fafac92c7453",
      "metadata": {
        "id": "1d60dcd4-514f-4efd-8b4a-fafac92c7453"
      },
      "outputs": [],
      "source": [
        "c = askgpt(\"Use the `sum` function to solve this: What is 6+3?\",\n",
        "           system = \"You must use the `sum` function instead of adding yourself.\",\n",
        "           functions=[schema(sums)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c"
      ],
      "metadata": {
        "id": "Z5mfzxAM5UUb",
        "outputId": "fb3491e4-44b6-4d24-d366-9fcf017f6e1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Z5mfzxAM5UUb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-8pdGB8YlRQq2XU7XviPWykf4mG2oc', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"a\": 6,\\n  \"b\": 3\\n}', name='sums'), tool_calls=None))], created=1707316335, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=22, prompt_tokens=83, total_tokens=105))"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cc8a9eb-64fc-4ce3-9f93-aee334fc8c65",
      "metadata": {
        "id": "5cc8a9eb-64fc-4ce3-9f93-aee334fc8c65",
        "outputId": "2469544e-6827-4cc7-d47c-e764e670c251",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"a\": 6,\\n  \"b\": 3\\n}', name='sums'), tool_calls=None)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "m = c.choices[0].message\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a881835-83a2-4fbc-9796-409831dcdb36",
      "metadata": {
        "id": "5a881835-83a2-4fbc-9796-409831dcdb36",
        "outputId": "1a196d4e-2db2-4840-f1ff-2d1b415690d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"a\": 6,\n",
            "  \"b\": 3\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "k = m.function_call.arguments\n",
        "print(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f32b172-7730-4c58-a999-5d3800e8c2a4",
      "metadata": {
        "id": "3f32b172-7730-4c58-a999-5d3800e8c2a4"
      },
      "outputs": [],
      "source": [
        "funcs_ok = {'sums', 'python'}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c.choices[0].message.function_call.arguments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ewFwxCMx_9SN",
        "outputId": "30d6597d-217c-4781-d874-e99afa9784ed"
      },
      "id": "ewFwxCMx_9SN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import math\\nmath.factorial(12)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9853a78e-8643-4b5b-9b4a-a360c8443344",
      "metadata": {
        "id": "9853a78e-8643-4b5b-9b4a-a360c8443344"
      },
      "outputs": [],
      "source": [
        "def call_func(c):\n",
        "    fc = c.choices[0].message.function_call\n",
        "    if fc.name not in funcs_ok: return print(f'Not allowed: {fc.name}')\n",
        "    f = globals()[fc.name]\n",
        "    try:\n",
        "        return f(**json.loads(fc.arguments))\n",
        "    except ValueError:\n",
        "        return f(fc.arguments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce6be825-44fa-4bc9-a83a-7ecbcb6c2729",
      "metadata": {
        "id": "ce6be825-44fa-4bc9-a83a-7ecbcb6c2729",
        "outputId": "d87a3604-5c1e-4e84-b55c-18024f2b227b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "479001600"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ],
      "source": [
        "call_func(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5ebf08c-2c3f-4c73-bd41-2f0d0a6ca3c2",
      "metadata": {
        "id": "a5ebf08c-2c3f-4c73-bd41-2f0d0a6ca3c2"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "\n",
        "def run(code):\n",
        "    tree = ast.parse(code)\n",
        "    last_node = tree.body[-1] if tree.body else None\n",
        "\n",
        "    # If the last node is an expression, modify the AST to capture the result\n",
        "    if isinstance(last_node, ast.Expr):\n",
        "        tgts = [ast.Name(id='_result', ctx=ast.Store())]\n",
        "        assign = ast.Assign(targets=tgts, value=last_node.value)\n",
        "        tree.body[-1] = ast.fix_missing_locations(assign)\n",
        "\n",
        "    ns = {}\n",
        "    exec(compile(tree, filename='<ast>', mode='exec'), ns)\n",
        "    return ns.get('_result', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37aa6983-d9af-40e8-b438-ed8573399020",
      "metadata": {
        "id": "37aa6983-d9af-40e8-b438-ed8573399020",
        "outputId": "ab2432ca-9751-46f5-ff05-3c3bb6df39e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ],
      "source": [
        "run(\"\"\"\n",
        "a=1\n",
        "b=2\n",
        "a+b\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2074acd-8a49-443b-89c6-cfc689ecad6d",
      "metadata": {
        "id": "d2074acd-8a49-443b-89c6-cfc689ecad6d"
      },
      "outputs": [],
      "source": [
        "def python(code:str, safe_mode:bool=False):\n",
        "    \"Return result of executing `code` using python. If execution not permitted, returns `#FAIL#`\"\n",
        "    if safe_mode:\n",
        "        go = input(f'Proceed with execution?\\n```\\n{code}\\n```\\n')\n",
        "        if go.lower()!='y': return '#FAIL#'\n",
        "    return run(code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02760caf-6d0d-4f5d-a7c6-cd8df5ee1a4b",
      "metadata": {
        "id": "02760caf-6d0d-4f5d-a7c6-cd8df5ee1a4b"
      },
      "outputs": [],
      "source": [
        "c = askgpt(\"What is 12 factorial?\",\n",
        "           system = \"Use python for any required computations.\",\n",
        "           functions=[schema(python)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def code_response(c, repl=True):\n",
        "    txt_out = response(c)\n",
        "    if txt_out == None: txt_out = ''\n",
        "    if 'function_call' not in dir(c.choices[0].message):\n",
        "        print(txt_out)\n",
        "        return  # No code output\n",
        "    code = c.choices[0].message.function_call.arguments\n",
        "    if code[0] == '{': code = json.loads(code)['code']\n",
        "    txt_out += f'\\n==========\\n{code}\\n==========\\n>>> '\n",
        "    result = run(code)\n",
        "    print(txt_out)\n",
        "    return result"
      ],
      "metadata": {
        "id": "15kV8iC0XZJ1"
      },
      "id": "15kV8iC0XZJ1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fe5d796-c602-471f-bb58-bb876039bc39",
      "metadata": {
        "id": "5fe5d796-c602-471f-bb58-bb876039bc39",
        "outputId": "9a93257b-79ee-4696-97d0-e07d5df496fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "479001600"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ],
      "source": [
        "call_func(c)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_response(c)"
      ],
      "metadata": {
        "id": "00TTFia8XrLN",
        "outputId": "bcc35d5e-ed93-4678-8e06-48ae1be886a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "00TTFia8XrLN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========\n",
            "import math\n",
            "\n",
            "factorial = math.factorial(12)\n",
            "factorial\n",
            "==========\n",
            ">>> \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "479001600"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using Python's exec & eval"
      ],
      "metadata": {
        "id": "89hOEyvHXIlI"
      },
      "id": "89hOEyvHXIlI"
    },
    {
      "cell_type": "code",
      "source": [
        "exec_schema = {\n",
        "    'name': 'exec',\n",
        "    'description': 'Execute the given source Python code',\n",
        "    'parameters': {\n",
        "        'title': 'Input for `exec`',\n",
        "        'type': 'object',\n",
        "        'properties': {'source': {'title': 'S', 'type': 'string'}},\n",
        "        'required': ['source']}}"
      ],
      "metadata": {
        "id": "pVDtEgUaDLGy"
      },
      "id": "pVDtEgUaDLGy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def code_response(c, repl=True):\n",
        "    txt_out = response(c)\n",
        "    if txt_out == None: txt_out = ''\n",
        "    msg = c.choices[0].message\n",
        "    if 'function_call' not in dir(msg) or msg.function_call is None:\n",
        "        print(txt_out)\n",
        "        return  # No code output\n",
        "    code = msg.function_call.arguments\n",
        "    if code[0] == '{': code = json.loads(code)['source']\n",
        "    txt_out += f'\\n==========\\n{code}\\n==========\\n>>> '\n",
        "    if repl:\n",
        "        code_body = '\\n'.join(code.split('\\n')[:-1])\n",
        "        code_footer = code.split('\\n')[-1]\n",
        "        exec(code_body, locals())\n",
        "        result = eval(code_footer, locals())\n",
        "        txt_out += str(result)\n",
        "    else:\n",
        "        exec(code, locals())\n",
        "        result = None\n",
        "    print(txt_out)\n",
        "    return result"
      ],
      "metadata": {
        "id": "CZIE3OaTEXKP"
      },
      "id": "CZIE3OaTEXKP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = askgpt(\"What is 12 factorial?\",\n",
        "           system = \"Use python for any required computations.\",\n",
        "           functions=[exec_schema])"
      ],
      "metadata": {
        "id": "wlxgggW8hIO-"
      },
      "id": "wlxgggW8hIO-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "factorial_result = code_response(c, repl=True)"
      ],
      "metadata": {
        "id": "AQUn1nsnbuqn",
        "outputId": "efedc1b5-2d2c-48a9-cc43-fd148231a5fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AQUn1nsnbuqn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The factorial of a number n, denoted as n!, is the product of all positive integers less than or equal to n. \n",
            "\n",
            "The factorial of 12, written as 12!, is:\n",
            "\n",
            "12! = 12 * 11 * 10 * 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2 * 1\n",
            "\n",
            "To calculate this, we can use Python.\n",
            "==========\n",
            "import math\n",
            "\n",
            "factorial = math.factorial(12)\n",
            "factorial\n",
            "==========\n",
            ">>> 479001600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "factorial_result"
      ],
      "metadata": {
        "id": "I6CD-vb7qUPV",
        "outputId": "bd49afb1-b4cf-4104-feab-64ea71884b02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "I6CD-vb7qUPV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "479001600"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_python(s):\n",
        "    c = askgpt(s,\n",
        "           system = \"Use python for any required computations.\",\n",
        "           functions=[exec_schema])\n",
        "    result = code_response(c, repl=True)\n",
        "    return result"
      ],
      "metadata": {
        "id": "0HwdarfMiUhe"
      },
      "id": "0HwdarfMiUhe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prime_question = \"What is the largest prime less than 434?\"\n",
        "prime_result = ask_python(prime_question)"
      ],
      "metadata": {
        "id": "IRVSIxrqit4l",
        "outputId": "13c17e7e-37ed-4d54-d991-706b16f10926",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IRVSIxrqit4l",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========\n",
            "import sympy\n",
            "sympy.prevprime(434)\n",
            "==========\n",
            ">>> 433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Using result in later calls"
      ],
      "metadata": {
        "id": "EiQWJStKa8L1"
      },
      "id": "EiQWJStKa8L1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4e6bcd6-c23e-4ae8-8d38-78dae20ca176",
      "metadata": {
        "id": "c4e6bcd6-c23e-4ae8-8d38-78dae20ca176"
      },
      "outputs": [],
      "source": [
        "c = ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    functions=[exec_schema],\n",
        "    messages=[{\"role\": \"user\", \"content\": prime_question},\n",
        "              {\"role\": \"function\", \"name\": \"exec\", \"content\": str(prime_result)}])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response(c))"
      ],
      "metadata": {
        "id": "ImVNh39guvwd",
        "outputId": "341130cc-ae60-465b-a957-c3e60d5cdbe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ImVNh39guvwd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The largest prime number less than 434 is 433.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### And we didn't break its basic use!"
      ],
      "metadata": {
        "id": "3j86PEJHbGLf"
      },
      "id": "3j86PEJHbGLf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bef5cc05-0531-422b-9367-e7b90d784a54",
      "metadata": {
        "id": "bef5cc05-0531-422b-9367-e7b90d784a54"
      },
      "outputs": [],
      "source": [
        "c = askgpt(\"What is the capital of France?\",\n",
        "           system = \"Use python for any required computations.\",\n",
        "           functions=[exec_schema])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "112bc3db-5aa4-41ba-95df-1651916d7f0b",
      "metadata": {
        "id": "112bc3db-5aa4-41ba-95df-1651916d7f0b",
        "outputId": "e52621b4-d015-473e-e4ac-6b0a3d5a66e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of France is Paris.\n"
          ]
        }
      ],
      "source": [
        "code_response(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction from current execution!"
      ],
      "metadata": {
        "id": "nfDbp1xlPofA"
      },
      "id": "nfDbp1xlPofA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comments are not saved in history_manager!!! We have to use strings at the start of the cell."
      ],
      "metadata": {
        "id": "Y9M1VXOTacVo"
      },
      "id": "Y9M1VXOTacVo"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_history(): return get_ipython().history_manager.input_hist_raw\n",
        "def clear_history(): get_ipython().history_manager.input_hist_raw = []"
      ],
      "metadata": {
        "id": "uxE6fP4NN_2C"
      },
      "id": "uxE6fP4NN_2C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_cell():\n",
        "    _func_call = '\\n' + complete_cell.__name__ + '()'\n",
        "    raw = get_history()\n",
        "    nb = '\\n\\n\\n#! CELL\\n\\n'.join(raw).split(_func_call)[0]\n",
        "    c = Completion.create(prompt=nb,\n",
        "                      model=\"gpt-3.5-turbo-instruct\",\n",
        "                      echo=False,\n",
        "                      best_of=1,\n",
        "                      stop= \"#! CELL\")\n",
        "    return response(c).strip()"
      ],
      "metadata": {
        "id": "MyUOIP21RUry"
      },
      "id": "MyUOIP21RUry",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clear_history()"
      ],
      "metadata": {
        "id": "IaqM2XJCdq0k"
      },
      "id": "IaqM2XJCdq0k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Characters'''\n",
        "'abcdefghijklmnopqrstuvwxyz'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GzdjKp1SUSIb",
        "outputId": "2b73a0d8-2bf5-4173-8432-ca094a7ba9a2"
      },
      "id": "GzdjKp1SUSIb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Chinese characters'''\n",
        "print(complete_cell())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP8XHqzzUR_c",
        "outputId": "2292ddfc-4b04-44da-f006-44fb99cb6e8c"
      },
      "id": "AP8XHqzzUR_c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "中国字\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b7c7e1d-ad0c-4668-a10d-569ba6b7aa04",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "1b7c7e1d-ad0c-4668-a10d-569ba6b7aa04"
      },
      "source": [
        "## Open source models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "009f4187-ffd6-43ba-b5f1-709b5a3dcf1b"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -qq\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch"
      ],
      "id": "009f4187-ffd6-43ba-b5f1-709b5a3dcf1b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0fa7911-c191-4945-97aa-6daff95970d7"
      },
      "source": [
        "- [HF leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n",
        "- [fasteval](https://fasteval.github.io/FastEval/)"
      ],
      "id": "c0fa7911-c191-4945-97aa-6daff95970d7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e1ed7e9-fbf5-463c-9ff8-2f22c75088bf"
      },
      "outputs": [],
      "source": [
        "mn = \"meta-llama/Llama-2-7b-hf\""
      ],
      "id": "3e1ed7e9-fbf5-463c-9ff8-2f22c75088bf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94600cb9-2a64-47e2-aca3-99a72985157f"
      },
      "outputs": [],
      "source": [
        "tokr = AutoTokenizer.from_pretrained(mn)\n",
        "prompt = \"Jeremy Howard is a \"\n",
        "toks = tokr(prompt, return_tensors=\"pt\")"
      ],
      "id": "94600cb9-2a64-47e2-aca3-99a72985157f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20605293-b31f-4db7-b6a5-0ef662d89441"
      },
      "outputs": [],
      "source": [
        "toks"
      ],
      "id": "20605293-b31f-4db7-b6a5-0ef662d89441"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c20ab287-7d80-47c2-870f-e2ee6bfc4492"
      },
      "outputs": [],
      "source": [
        "tokr.batch_decode(toks['input_ids'])"
      ],
      "id": "c20ab287-7d80-47c2-870f-e2ee6bfc4492"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb16cb3e-0634-4eed-b2b4-1422ecce9cc3"
      },
      "outputs": [],
      "source": [
        "# model = AutoModelForCausalLM.from_pretrained(mn, device_map=0, load_in_8bit=True)"
      ],
      "id": "bb16cb3e-0634-4eed-b2b4-1422ecce9cc3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab3ad5dc-51b4-48ca-92ae-5027069771c1"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# res = model.generate(**toks.to(\"cuda\"), max_new_tokens=15).to('cpu')\n",
        "# res"
      ],
      "id": "ab3ad5dc-51b4-48ca-92ae-5027069771c1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af5a23fc-aa2a-4ce2-92c7-75364130e4e6"
      },
      "outputs": [],
      "source": [
        "# tokr.batch_decode(res)"
      ],
      "id": "af5a23fc-aa2a-4ce2-92c7-75364130e4e6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15311da3-bfc0-4453-b4a8-6a9773db626b"
      },
      "outputs": [],
      "source": [
        "# model = AutoModelForCausalLM.from_pretrained(mn, device_map=0, torch_dtype=torch.bfloat16)"
      ],
      "id": "15311da3-bfc0-4453-b4a8-6a9773db626b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c15c511b-f5f7-46e2-8fbc-514262117e15"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# res = model.generate(**toks.to(\"cuda\"), max_new_tokens=15).to('cpu')\n",
        "# res"
      ],
      "id": "c15c511b-f5f7-46e2-8fbc-514262117e15"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c581df92-b1cd-4c02-8cde-b2de96d302dd"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained('TheBloke/Llama-2-7b-Chat-GPTQ', device_map=0, torch_dtype=torch.float16)"
      ],
      "id": "c581df92-b1cd-4c02-8cde-b2de96d302dd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f47b5b7-ea46-41f0-8338-027b13e0586c"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "res = model.generate(**toks.to(\"cuda\"), max_new_tokens=15).to('cpu')\n",
        "res"
      ],
      "id": "8f47b5b7-ea46-41f0-8338-027b13e0586c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb4b60cd-859b-4b3a-b76d-e9eddcdf7cf0"
      },
      "outputs": [],
      "source": [
        "# mn = 'TheBloke/Llama-2-13B-GPTQ'\n",
        "# model = AutoModelForCausalLM.from_pretrained(mn, device_map=0, torch_dtype=torch.float16)"
      ],
      "id": "bb4b60cd-859b-4b3a-b76d-e9eddcdf7cf0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da90406b-b8a8-4939-a0e9-18c933b62a7c"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# res = model.generate(**toks.to(\"cuda\"), max_new_tokens=15).to('cpu')\n",
        "# res"
      ],
      "id": "da90406b-b8a8-4939-a0e9-18c933b62a7c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c88d11f8-e41d-4db8-91f2-3e2f695a4d00"
      },
      "outputs": [],
      "source": [
        "def gen(p, maxlen=15, sample=True):\n",
        "    toks = tokr(p, return_tensors=\"pt\")\n",
        "    res = model.generate(**toks.to(\"cuda\"), max_new_tokens=maxlen, do_sample=sample).to('cpu')\n",
        "    return tokr.batch_decode(res)"
      ],
      "id": "c88d11f8-e41d-4db8-91f2-3e2f695a4d00"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc143703-4fc7-46ce-8c59-cdeec52e7830"
      },
      "outputs": [],
      "source": [
        "gen(prompt, 50)"
      ],
      "id": "dc143703-4fc7-46ce-8c59-cdeec52e7830"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18fb80c0-8664-498c-bb7d-370de8bf6ca7"
      },
      "source": [
        "#### [StableBeluga-7B](https://huggingface.co/stabilityai/StableBeluga-7B)"
      ],
      "id": "18fb80c0-8664-498c-bb7d-370de8bf6ca7"
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "BV4pyFlfjrPf"
      },
      "id": "BV4pyFlfjrPf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd343d7b-ef48-4077-bc97-deeec24e324b"
      },
      "outputs": [],
      "source": [
        "mn = \"stabilityai/StableBeluga-7B\"\n",
        "model = AutoModelForCausalLM.from_pretrained(mn, device_map=0, torch_dtype=torch.bfloat16)"
      ],
      "id": "dd343d7b-ef48-4077-bc97-deeec24e324b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "432074d6-5d04-4afe-b6cb-06d4412023d6"
      },
      "outputs": [],
      "source": [
        "sb_sys = \"You are Stable Beluga, an AI that follows instructions extremely well. Help as much as you can.\\n\\n\""
      ],
      "id": "432074d6-5d04-4afe-b6cb-06d4412023d6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1392331-731e-416d-be2d-bc172167e25e"
      },
      "outputs": [],
      "source": [
        "def mk_prompt(user, syst=sb_sys): return f\"### System:\\n{syst}\\n### User:\\n{user}\\n\\n### Assistant:\\n\""
      ],
      "id": "e1392331-731e-416d-be2d-bc172167e25e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a68af5c-5714-4736-9569-5619c54b2bdb"
      },
      "outputs": [],
      "source": [
        "ques = \"Who is Jeremy Howard?\""
      ],
      "id": "5a68af5c-5714-4736-9569-5619c54b2bdb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90b5f8e8-a16c-40e6-8dc6-c467ffaa6268"
      },
      "outputs": [],
      "source": [
        "gen(mk_prompt(ques), 150)"
      ],
      "id": "90b5f8e8-a16c-40e6-8dc6-c467ffaa6268"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1a0cfd5-4c64-4591-be83-77b846c41e57"
      },
      "source": [
        "[OpenOrca/Platypus 2](https://huggingface.co/Open-Orca/OpenOrca-Platypus2-13B)"
      ],
      "id": "b1a0cfd5-4c64-4591-be83-77b846c41e57"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c7c670a-17aa-41da-8b61-19db6a5dc019"
      },
      "outputs": [],
      "source": [
        "mn = 'TheBloke/OpenOrca-Platypus2-13B-GPTQ'\n",
        "model = AutoModelForCausalLM.from_pretrained(mn, device_map=0, torch_dtype=torch.float16)"
      ],
      "id": "6c7c670a-17aa-41da-8b61-19db6a5dc019"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2a267f4-396d-4852-9352-0ca90c0c8441"
      },
      "outputs": [],
      "source": [
        "def mk_oo_prompt(user): return f\"### Instruction: {user}\\n\\n### Response:\\n\""
      ],
      "id": "d2a267f4-396d-4852-9352-0ca90c0c8441"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b931d9c6-69c6-4385-b118-e5ad56781ba6"
      },
      "outputs": [],
      "source": [
        "gen(mk_oo_prompt(ques), 150)"
      ],
      "id": "b931d9c6-69c6-4385-b118-e5ad56781ba6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Retrieval augmentation"
      ],
      "metadata": {
        "id": "47Ls2YG3XGeX"
      },
      "id": "47Ls2YG3XGeX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1540a0c4-9266-4d7d-96a1-8d47d2fb737f",
      "metadata": {
        "id": "1540a0c4-9266-4d7d-96a1-8d47d2fb737f"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia-api\n",
        "from wikipediaapi import Wikipedia"
      ],
      "metadata": {
        "id": "V2qX9gbk4LDp"
      },
      "id": "V2qX9gbk4LDp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "618d9520-54e7-4f31-8363-2cdd3c3668ad",
      "metadata": {
        "id": "618d9520-54e7-4f31-8363-2cdd3c3668ad"
      },
      "outputs": [],
      "source": [
        "wiki = Wikipedia('JeremyHowardBot/0.0', 'en')\n",
        "jh_page = wiki.page('Jeremy_Howard_(entrepreneur)').text\n",
        "jh_page = jh_page.split('\\nReferences\\n')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53a0689a-ab59-431b-838d-33cae6f6500a",
      "metadata": {
        "id": "53a0689a-ab59-431b-838d-33cae6f6500a"
      },
      "outputs": [],
      "source": [
        "print(jh_page[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3ded6a2-3665-416c-8d98-063f04aae0a0",
      "metadata": {
        "id": "d3ded6a2-3665-416c-8d98-063f04aae0a0"
      },
      "outputs": [],
      "source": [
        "len(jh_page.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f37d5fb1-7182-45a0-bd4e-6a39837ce20b",
      "metadata": {
        "id": "f37d5fb1-7182-45a0-bd4e-6a39837ce20b"
      },
      "outputs": [],
      "source": [
        "def mk_prompt_context(question, context):\n",
        "    return f\"\"\"Answer the question with the help of the provided context.\\n\\n## Context\\n\\n{context}\\n\\n## Question\\n\\n{question}## Answer\\n\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6a7fb6d-d771-4eca-8e6f-29d90ade348a",
      "metadata": {
        "id": "d6a7fb6d-d771-4eca-8e6f-29d90ade348a"
      },
      "outputs": [],
      "source": [
        "res = gen(mk_prompt_context(ques, jh_page), 300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85b10234-e1e6-4a1e-86a7-206e46e916f2",
      "metadata": {
        "id": "85b10234-e1e6-4a1e-86a7-206e46e916f2"
      },
      "outputs": [],
      "source": [
        "print(res[0].split('## Answer\\n')[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0cdc342-a89c-4149-b3be-d4b5bf0f6f28",
      "metadata": {
        "id": "a0cdc342-a89c-4149-b3be-d4b5bf0f6f28"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers -qq\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e225ca13-1735-42e9-b162-66268fce5218",
      "metadata": {
        "id": "e225ca13-1735-42e9-b162-66268fce5218"
      },
      "outputs": [],
      "source": [
        "emb_model = SentenceTransformer(\"BAAI/bge-small-en-v1.5\", device=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c636ed79-45ed-4728-9dca-1c86d282a1c4",
      "metadata": {
        "id": "c636ed79-45ed-4728-9dca-1c86d282a1c4"
      },
      "outputs": [],
      "source": [
        "jh = jh_page.split('\\n\\n')[0]\n",
        "print(jh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b0ad4ca-499a-4454-a215-4f5a676d68ed",
      "metadata": {
        "id": "1b0ad4ca-499a-4454-a215-4f5a676d68ed"
      },
      "outputs": [],
      "source": [
        "tb_page = wiki.page('Tony_Blair').text.split('\\nReferences\\n')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26b28c6d-13ef-421a-865d-c311fb9fb2ae",
      "metadata": {
        "id": "26b28c6d-13ef-421a-865d-c311fb9fb2ae"
      },
      "outputs": [],
      "source": [
        "tb = tb_page.split('\\n\\n')[0]\n",
        "print(tb[:380])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3173701f-1533-4eef-b080-3b771f2ba031",
      "metadata": {
        "id": "3173701f-1533-4eef-b080-3b771f2ba031"
      },
      "outputs": [],
      "source": [
        "q_emb,jh_emb,tb_emb = emb_model.encode([ques,jh,tb], convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6237634d-3708-477d-97e3-34dd7900f4eb",
      "metadata": {
        "id": "6237634d-3708-477d-97e3-34dd7900f4eb"
      },
      "outputs": [],
      "source": [
        "tb_emb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19638b95-f0dd-4605-8b04-3a0f9f9944b0",
      "metadata": {
        "id": "19638b95-f0dd-4605-8b04-3a0f9f9944b0"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a3937ac-45b7-4635-9f93-d1bcd1d6a016",
      "metadata": {
        "id": "8a3937ac-45b7-4635-9f93-d1bcd1d6a016"
      },
      "outputs": [],
      "source": [
        "F.cosine_similarity(q_emb, jh_emb, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c8beb5e-4a8c-4049-b42b-3acce573dd59",
      "metadata": {
        "id": "6c8beb5e-4a8c-4049-b42b-3acce573dd59"
      },
      "outputs": [],
      "source": [
        "F.cosine_similarity(q_emb, tb_emb, dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8473a6bc-fd25-4698-99d5-864ed1d5b40b",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "8473a6bc-fd25-4698-99d5-864ed1d5b40b"
      },
      "source": [
        "### Private GPTs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "037bc313-052d-46b3-8938-fef988126dcb",
      "metadata": {
        "id": "037bc313-052d-46b3-8938-fef988126dcb"
      },
      "source": [
        "- [Sooo many](https://github.com/h2oai/h2ogpt/blob/main/docs/README_LangChain.md#what-is-h2ogpts-langchain-integration-like)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1948c419-4f04-4832-848c-a0c52dcc6a90",
      "metadata": {
        "id": "1948c419-4f04-4832-848c-a0c52dcc6a90"
      },
      "source": [
        "## Fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03c2871f-e0fe-4891-b68e-05b6ca7373d8",
      "metadata": {
        "id": "03c2871f-e0fe-4891-b68e-05b6ca7373d8"
      },
      "outputs": [],
      "source": [
        "import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54366155-5ac3-4e75-8638-9e2ecf263c2f",
      "metadata": {
        "id": "54366155-5ac3-4e75-8638-9e2ecf263c2f"
      },
      "source": [
        "[knowrohit07/know_sql](https://huggingface.co/datasets/knowrohit07/know_sql)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed118caf-3e94-4773-a182-f2d346ced836",
      "metadata": {
        "id": "ed118caf-3e94-4773-a182-f2d346ced836"
      },
      "outputs": [],
      "source": [
        "ds = datasets.load_dataset('knowrohit07/know_sql', revision='f33425d13f9e8aab1b46fa945326e9356d6d5726')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d444ac3-a49f-4fcf-bcf4-c12c410d7aba",
      "metadata": {
        "id": "6d444ac3-a49f-4fcf-bcf4-c12c410d7aba"
      },
      "outputs": [],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec155bd-5eb8-4eef-bdbc-b430a26fd11e",
      "metadata": {
        "id": "8ec155bd-5eb8-4eef-bdbc-b430a26fd11e"
      },
      "outputs": [],
      "source": [
        "trn = ds['train']\n",
        "trn[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e23cb868-10e4-4fcc-b8ba-9178ef3dac7e",
      "metadata": {
        "id": "e23cb868-10e4-4fcc-b8ba-9178ef3dac7e"
      },
      "source": [
        "`accelerate launch -m axolotl.cli.train sql.yml`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae6a579c-086e-46e4-a184-de5b71f4d80b",
      "metadata": {
        "id": "ae6a579c-086e-46e4-a184-de5b71f4d80b"
      },
      "outputs": [],
      "source": [
        "tst = dict(**trn[3])\n",
        "tst['question'] = 'Get the count of competition hosts by theme.'\n",
        "tst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "229c5fb9-0dff-460c-af1a-192fdec26ecd",
      "metadata": {
        "id": "229c5fb9-0dff-460c-af1a-192fdec26ecd"
      },
      "outputs": [],
      "source": [
        "fmt = \"\"\"SYSTEM: Use the following contextual information to concisely answer the question.\n",
        "\n",
        "USER: {}\n",
        "===\n",
        "{}\n",
        "ASSISTANT:\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feca892e-64f0-48d2-832e-0d8ceb9855d2",
      "metadata": {
        "id": "feca892e-64f0-48d2-832e-0d8ceb9855d2"
      },
      "outputs": [],
      "source": [
        "def sql_prompt(d): return fmt.format(d[\"context\"], d[\"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "058b0f4a-8fe0-4612-8584-451e8d04fe2d",
      "metadata": {
        "id": "058b0f4a-8fe0-4612-8584-451e8d04fe2d"
      },
      "outputs": [],
      "source": [
        "print(sql_prompt(tst))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86827af0-6cf0-43d0-b50a-fe080de83f48",
      "metadata": {
        "id": "86827af0-6cf0-43d0-b50a-fe080de83f48"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from peft import PeftModel\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d33b0c-4973-4bc8-beef-aae7915f4b01",
      "metadata": {
        "id": "e6d33b0c-4973-4bc8-beef-aae7915f4b01"
      },
      "outputs": [],
      "source": [
        "ax_model = '/home/jhoward/git/ext/axolotl/qlora-out'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b7082fe-b668-4f11-abf8-548996ea3004",
      "metadata": {
        "id": "7b7082fe-b668-4f11-abf8-548996ea3004"
      },
      "outputs": [],
      "source": [
        "tokr = AutoTokenizer.from_pretrained('meta-llama/Llama-2-7b-hf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fec3b5ad-0577-4867-b2d8-9143800c9f54",
      "metadata": {
        "id": "fec3b5ad-0577-4867-b2d8-9143800c9f54"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained('meta-llama/Llama-2-7b-hf',\n",
        "                                             torch_dtype=torch.bfloat16, device_map=0)\n",
        "\n",
        "# TODO: Get config to Drive\n",
        "model = PeftModel.from_pretrained(model, ax_model)\n",
        "model = model.merge_and_unload()\n",
        "model.save_pretrained('sql-model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a58bc69-6ea6-416a-baa9-db3338451d60",
      "metadata": {
        "id": "8a58bc69-6ea6-416a-baa9-db3338451d60"
      },
      "outputs": [],
      "source": [
        "toks = tokr(sql_prompt(tst), return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a057289b-0645-4142-8db2-cc823cc34898",
      "metadata": {
        "id": "a057289b-0645-4142-8db2-cc823cc34898"
      },
      "outputs": [],
      "source": [
        "res = model.generate(**toks.to(\"cuda\"), max_new_tokens=250).to('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80db7d77-89e2-4006-a1b2-78b807de1a68",
      "metadata": {
        "id": "80db7d77-89e2-4006-a1b2-78b807de1a68"
      },
      "outputs": [],
      "source": [
        "print(tokr.batch_decode(res)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "991d4a93-dab8-4777-82d2-301c494deba0",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "991d4a93-dab8-4777-82d2-301c494deba0"
      },
      "source": [
        "## [llama.cpp](https://github.com/abetlen/llama-cpp-python)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dc9d6e4-5b25-4d11-8748-dc4f0bc98069",
      "metadata": {
        "id": "0dc9d6e4-5b25-4d11-8748-dc4f0bc98069"
      },
      "source": [
        "[TheBloke/Llama-2-7b-Chat-GGUF](https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f33831f-8c71-47dc-a131-9a6733d68198",
      "metadata": {
        "id": "6f33831f-8c71-47dc-a131-9a6733d68198"
      },
      "outputs": [],
      "source": [
        "!pip install llama_cpp_python -qq\n",
        "from llama_cpp import Llama"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf"
      ],
      "metadata": {
        "id": "w9-ince1abRK"
      },
      "id": "w9-ince1abRK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b824b6c-96cd-4bfe-a615-b3ba4543a92d",
      "metadata": {
        "id": "3b824b6c-96cd-4bfe-a615-b3ba4543a92d"
      },
      "outputs": [],
      "source": [
        "llm = Llama(model_path=\"/content/llama-2-7b-chat.Q4_K_M.gguf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c95a95b9-7c9f-499a-a72a-ad626da8c3f5",
      "metadata": {
        "id": "c95a95b9-7c9f-499a-a72a-ad626da8c3f5"
      },
      "outputs": [],
      "source": [
        "output = llm(\"Q: Name the planets in the solar system? A: \", max_tokens=32, stop=[\"Q:\", \"\\n\"], echo=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9f89cec-5453-4d67-85b2-c937ceb03a54",
      "metadata": {
        "id": "f9f89cec-5453-4d67-85b2-c937ceb03a54"
      },
      "outputs": [],
      "source": [
        "print(output['choices'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3yUZ3hsMa7Q8"
      },
      "id": "3yUZ3hsMa7Q8",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}