{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Santiago-R/aprende/blob/main/lm-hackers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [A hacker's guide to Language Models](https://colab.research.google.com/github/fastai/lm-hackers/blob/main/lm-hackers.ipynb#scrollTo=0b017bfc-5be0-4e41-9fa1-9f685c3b0de5)\n"
      ],
      "metadata": {
        "id": "8PCrJ_dZIOiQ"
      },
      "id": "8PCrJ_dZIOiQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial restart"
      ],
      "metadata": {
        "id": "hD6Q63G3FXx3"
      },
      "id": "hD6Q63G3FXx3"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import importlib\n",
        "a_spec = importlib.util.find_spec('accelerate')\n",
        "b_spec = importlib.util.find_spec('bitsandbytes')\n",
        "found = a_spec is not None and b_spec is not None\n",
        "\n",
        "if found: print('Dependencies installed in previous run ‚úîÔ∏è')\n",
        "else:\n",
        "    !pip install accelerate -qq\n",
        "    !pip install bitsandbytes -qq\n",
        "    !pip install auto-gptq -qq\n",
        "    !pip install optimum -qq\n",
        "    !pip install vllm\n",
        "\n",
        "    print('\\nDependency installation requires restart --> killing runtime üíÄ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbEyUpZ1FXb_",
        "outputId": "2a1300ac-fabd-475f-913f-d491f7b11720"
      },
      "id": "pbEyUpZ1FXb_",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependencies installed in previous run ‚úîÔ∏è\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not found:\n",
        "    os.kill(os.getpid(), 9)  # Kill runtime if required"
      ],
      "metadata": {
        "id": "Gli7P5_ARWOT"
      },
      "id": "Gli7P5_ARWOT",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "pbMRhlx6ffxA"
      },
      "id": "pbMRhlx6ffxA"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # , force_remount=True)"
      ],
      "metadata": {
        "id": "lKUyTtKkduDt",
        "outputId": "867cb71a-16c1-4f73-8785-89b87863842f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lKUyTtKkduDt",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tokenize\n",
        "# from io import BytesIO"
      ],
      "metadata": {
        "id": "mnQzskuV91G4"
      },
      "id": "mnQzskuV91G4",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load api keys as environvent variable (from Drive's api_keys.env)\n",
        "!pip install python-dotenv -qq\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(dotenv_path='/content/drive/MyDrive/LLM/api_keys.env')"
      ],
      "metadata": {
        "id": "pHmWz-Hv_bMg",
        "outputId": "e032fcc7-a7c1-42a5-f384-d48432d35e0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pHmWz-Hv_bMg",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "101f8f63-6a03-49c0-81b8-9173563f7420",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "101f8f63-6a03-49c0-81b8-9173563f7420"
      },
      "source": [
        "## OpenAI API with system prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "6564eb90-4a24-4a48-b898-5d4408ac2a65",
      "metadata": {
        "id": "6564eb90-4a24-4a48-b898-5d4408ac2a65"
      },
      "outputs": [],
      "source": [
        "!pip install openai -qq\n",
        "import openai\n",
        "client = openai.OpenAI()\n",
        "ChatCompletion = client.chat.completions\n",
        "Completion = client.completions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simple chat"
      ],
      "metadata": {
        "id": "uqarVrUjd94a"
      },
      "id": "uqarVrUjd94a"
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown  # , HTML"
      ],
      "metadata": {
        "id": "BMmHzjnaaEql"
      },
      "id": "BMmHzjnaaEql",
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewChat:\n",
        "    def __init__(self, p_sys=None, model=\"gpt-4o-mini\"):\n",
        "        self.messages = [{\"role\": \"system\", \"content\": p_sys}] if p_sys else []\n",
        "        self.model = model\n",
        "    def __call__(self, p):\n",
        "        self.messages.append({\"role\": \"user\", \"content\": p})\n",
        "        answer = ChatCompletion.create(\n",
        "            model=self.model,\n",
        "            messages=self.messages\n",
        "        ).choices[0].message.content\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
        "        return answer\n",
        "    def retry(self, index=-2):\n",
        "        assert (user_input:=self.messages[index])[\"role\"] == \"user\", \"can only retry answering a user request\"\n",
        "        self.messages = self.messages[:index]\n",
        "        return self(user_input[\"content\"])\n",
        "    def list_repr(self): return [f'###{m[\"role\"].upper()}\\n{m[\"content\"]}' for m in self.messages]\n",
        "    def __repr__(self, sep='\\n'): return sep.join(self.list_repr())\n",
        "    def display(self): display(Markdown(self.__repr__(sep='\\n***\\n')))"
      ],
      "metadata": {
        "id": "_Pm6wXmsHqSE"
      },
      "id": "_Pm6wXmsHqSE",
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = NewChat(model=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "id": "csEEE9O5d-W2"
      },
      "id": "csEEE9O5d-W2",
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = chat(\"\"\"\n",
        "I'd like to Make \"use\" HTML tags that are sub-elements of id \"PathCollection_1\" a bit bigger on hover. Brief response, please.\n",
        "\"\"\")\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "pthcFlAQd-N8",
        "outputId": "e9c4b46a-3aad-4eb6-964c-755367b2d2b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pthcFlAQd-N8",
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To make the `<use>` elements within the element with the id `PathCollection_1` bigger on hover, you can use the following CSS code:\n",
            "\n",
            "```css\n",
            "#PathCollection_1 use:hover {\n",
            "  transform: scale(1.2);  /* Adjust the scale factor as needed */\n",
            "  transition: transform 0.3s;  /* Smooth transition effect */\n",
            "}\n",
            "```\n",
            "\n",
            "This CSS will scale up the `<use>` elements when hovered over, providing a smooth transition effect. Adjust the scale factor to achieve the desired size.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = chat(\"\"\"\n",
        "Where would I place this style tag in my HTML?\n",
        "\"\"\")\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "PsC4X1DDfC55",
        "outputId": "98c95d6b-3af3-4de1-f252-e810256d50c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PsC4X1DDfC55",
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You can place the `<style>` tag within the `<head>` section of your HTML document. Here‚Äôs an example of how you can include it:\n",
            "\n",
            "```html\n",
            "<!DOCTYPE html>\n",
            "<html lang=\"en\">\n",
            "<head>\n",
            "  <meta charset=\"UTF-8\">\n",
            "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
            "  <title>Your Page Title</title>\n",
            "  <style>\n",
            "    #PathCollection_1 use:hover {\n",
            "      transform: scale(1.2); /* Adjust the scale factor as needed */\n",
            "      transition: transform 0.3s; /* Smooth transition effect */\n",
            "    }\n",
            "  </style>\n",
            "</head>\n",
            "<body>\n",
            "  <!-- Your HTML content goes here -->\n",
            "</body>\n",
            "</html>\n",
            "```\n",
            "\n",
            "Alternatively, if you are using an external CSS file, you could add the CSS rule to that file instead. Just make sure to link the external CSS file within the `<head>` section of your HTML:\n",
            "\n",
            "```html\n",
            "<head>\n",
            "  <link rel=\"stylesheet\" href=\"styles.css\">\n",
            "</head>\n",
            "```\n",
            "\n",
            "And then in `styles.css` file:\n",
            "\n",
            "```css\n",
            "#PathCollection_1 use:hover {\n",
            "  transform: scale(1.2); /* Adjust the scale factor as needed */\n",
            "  transition: transform 0.3s; /* Smooth transition effect */\n",
            "}\n",
            "```\n",
            "\n",
            "Placing the CSS in the `<head>` section or an external CSS file ensures that the styles are loaded before the HTML content is rendered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.display()"
      ],
      "metadata": {
        "id": "KaiCtagEgCHM",
        "outputId": "1d25a59a-7b9b-470b-e475-c792ceae1daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909
        }
      },
      "id": "KaiCtagEgCHM",
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###USER\n\nI'd like to Make \"use\" HTML tags that are sub-elements of id \"PathCollection_1\" a bit bigger on hover. Brief response, please.\n\n***\n###ASSISTANT\nTo make the `<use>` elements within the element with the id `PathCollection_1` bigger on hover, you can use the following CSS code:\n\n```css\n#PathCollection_1 use:hover {\n  transform: scale(1.2);  /* Adjust the scale factor as needed */\n  transition: transform 0.3s;  /* Smooth transition effect */\n}\n```\n\nThis CSS will scale up the `<use>` elements when hovered over, providing a smooth transition effect. Adjust the scale factor to achieve the desired size.\n***\n###USER\n\nWhere would I place this style tag in my HTML?\n\n***\n###ASSISTANT\nYou can place the `<style>` tag within the `<head>` section of your HTML document. Here‚Äôs an example of how you can include it:\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Your Page Title</title>\n  <style>\n    #PathCollection_1 use:hover {\n      transform: scale(1.2); /* Adjust the scale factor as needed */\n      transition: transform 0.3s; /* Smooth transition effect */\n    }\n  </style>\n</head>\n<body>\n  <!-- Your HTML content goes here -->\n</body>\n</html>\n```\n\nAlternatively, if you are using an external CSS file, you could add the CSS rule to that file instead. Just make sure to link the external CSS file within the `<head>` section of your HTML:\n\n```html\n<head>\n  <link rel=\"stylesheet\" href=\"styles.css\">\n</head>\n```\n\nAnd then in `styles.css` file:\n\n```css\n#PathCollection_1 use:hover {\n  transform: scale(1.2); /* Adjust the scale factor as needed */\n  transition: transform 0.3s; /* Smooth transition effect */\n}\n```\n\nPlacing the CSS in the `<head>` section or an external CSS file ensures that the styles are loaded before the HTML content is rendered."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Doctor's assistant (careful!)"
      ],
      "metadata": {
        "id": "SS1yZpAUPhR7"
      },
      "id": "SS1yZpAUPhR7"
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "UrPHkpWFPhR8"
      },
      "outputs": [],
      "source": [
        "p_sys = \"\"\"You are an expert doctor's assistant focused on enhancing individuals' overall wellness and physical performance beyond just treating illness.\n",
        "You will aid doctors in finding possible causes and treatment options for patiens' issues.\n",
        "\n",
        "Input: Summary of a patient's issue\n",
        "Output: A list of underlying causes, each with a connection to symptoms and its potential solution, for the doctor to evaluate.\n",
        "\"\"\""
      ],
      "id": "UrPHkpWFPhR8"
    },
    {
      "cell_type": "code",
      "source": [
        "# qa = gen_qa_sys(p_sys)\n",
        "chat = NewChat(p_sys, model=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "id": "nWWk-OJaJTQP"
      },
      "id": "nWWk-OJaJTQP",
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_user = \"\"\"\n",
        "- 35 yo male, no history of illness.\n",
        "- Patient reports letargy in the morning, even after getting enough sleep, more often than not.\n",
        "- Muscle weakness in the first minutes to hours of the day, most noticeably lack of grip strength.\n",
        "- Hydration and coffee often help, but patient feels like they are not sufficient to get him to a normal state.\n",
        "\"\"\"\n",
        "\n",
        "answer = chat(p_user)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMOaLLH9G4ic",
        "outputId": "6ed23e39-8cd0-49c9-dacf-ee1feabc42ed"
      },
      "id": "LMOaLLH9G4ic",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Potential Underlying Causes and Solutions\n",
            "\n",
            "#### 1. **Sleep Apnea**\n",
            "   - **Connection to Symptoms:** Sleep apnea can disrupt sleep quality without the patient being aware, leading to morning lethargy and muscle weakness.\n",
            "   - **Potential Solution:** \n",
            "     - Conduct a sleep study (polysomnography) to diagnose sleep apnea.\n",
            "     - If diagnosed, CPAP (Continuous Positive Airway Pressure) therapy could be recommended.\n",
            "     - Lifestyle changes such as weight management, sleeping position changes, and avoiding alcohol before bed.\n",
            "\n",
            "#### 2. **Thyroid Dysfunction (Hypothyroidism)**\n",
            "   - **Connection to Symptoms:** Hypothyroidism can cause fatigue and muscle weakness, especially in the mornings.\n",
            "   - **Potential Solution:**\n",
            "     - Assess thyroid function through blood tests (TSH, T3, T4 levels).\n",
            "     - If hypothyroidism is confirmed, thyroid hormone replacement therapy (e.g., levothyroxine) could be prescribed.\n",
            "\n",
            "#### 3. **Nutritional Deficiencies (e.g., Vitamin D, B12)**\n",
            "   - **Connection to Symptoms:** Low levels of certain vitamins and minerals can lead to fatigue and muscle weakness.\n",
            "   - **Potential Solution:**\n",
            "     - Check vitamin and mineral levels through blood tests (e.g., Vitamin D, B12, Iron).\n",
            "     - Dietary adjustments or supplementation based on deficiency findings.\n",
            "\n",
            "#### 4. **Adrenal Insufficiency or Dysfunction**\n",
            "   - **Connection to Symptoms:** Issues with adrenal function can lead to inadequate cortisol production, resulting in morning fatigue and muscle weakness.\n",
            "   - **Potential Solution:**\n",
            "     - Test cortisol levels (morning cortisol test) and possibly ACTH stimulation test.\n",
            "     - If adrenal insufficiency is diagnosed, hormone replacement therapy may be necessary.\n",
            "\n",
            "#### 5. **Diabetes or Blood Sugar Irregularities**\n",
            "   - **Connection to Symptoms:** Blood sugar fluctuations can cause morning fatigue and muscle weakness.\n",
            "   - **Potential Solution:**\n",
            "     - Monitor blood glucose levels (fasting glucose, HbA1c).\n",
            "     - Diet modification, increased physical activity, and possibly medication if blood sugar levels are abnormal.\n",
            "\n",
            "#### 6. **Chronic Fatigue Syndrome (CFS)**\n",
            "   - **Connection to Symptoms:** CFS can lead to persistent fatigue that is not relieved by sleep and muscle weakness.\n",
            "   - **Potential Solution:**\n",
            "     - A thorough evaluation to rule out other conditions.\n",
            "     - Symptomatic treatment which may include graded exercise therapy (GET), cognitive behavioral therapy (CBT), and possibly medication for symptom management.\n",
            "\n",
            "#### 7. **Electrolyte Imbalance**\n",
            "   - **Connection to Symptoms:** Electrolyte imbalances can contribute to fatigue and muscle weakness.\n",
            "   - **Potential Solution:**\n",
            "     - Check serum electrolyte levels (e.g., sodium, potassium, calcium, magnesium).\n",
            "     - Correct any imbalances with appropriate dietary changes or supplements.\n",
            "\n",
            "#### 8. **Chronic Stress or Depression**\n",
            "   - **Connection to Symptoms:** Chronic stress or depression can affect energy levels and physical strength.\n",
            "   - **Potential Solution:**\n",
            "     - Screening for stress and depressive symptoms.\n",
            "     - Interventions such as counseling, lifestyle changes, or medication (antidepressants or anxiolytics) as appropriate.\n",
            "\n",
            "#### 9. **Medications or Substance Use**\n",
            "   - **Connection to Symptoms:** Certain medications or excessive use of substances (including caffeine) can cause morning lethargy and muscle weakness.\n",
            "   - **Potential Solution:**\n",
            "     - Review the patient's medication and substance use history.\n",
            "     - Adjust or change medications if needed, while educating on optimal caffeine consumption.\n",
            "\n",
            "---\n",
            "\n",
            "These potential underlying causes and solutions should be further evaluated through patient history, physical examination, and appropriate diagnostic testing. Each solution provides a pathway for targeted treatment to help alleviate the patient's symptoms.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = chat('How about magnesium defficiency?')\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdCjFri8aen9",
        "outputId": "c70e569b-ce95-4dab-94d6-097c2bbaca46"
      },
      "id": "HdCjFri8aen9",
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Magnesium Deficiency\n",
            "\n",
            "#### **Connection to Symptoms:**\n",
            "   - **Morning Lethargy:** Magnesium plays a critical role in energy production and regulation of sleep patterns. A deficiency can impair sleep quality, leading to morning lethargy.\n",
            "   - **Muscle Weakness:** Magnesium is essential for muscle function and relaxation. Low levels can result in muscle cramps, spasms, or weakness, affecting grip strength especially in the morning.\n",
            "\n",
            "#### **Potential Solution:**\n",
            "   - **Diagnostic Testing:** Measure serum magnesium levels through a blood test to confirm deficiency.\n",
            "   - **Dietary Adjustments:** Increase consumption of magnesium-rich foods such as leafy green vegetables, nuts, seeds, whole grains, and legumes.\n",
            "   - **Supplementation:** If dietary adjustments are insufficient, consider magnesium supplements after consulting with the doctor to determine the appropriate dosage.\n",
            "   - **Hydration:** Continue maintaining good hydration, as dehydration can exacerbate magnesium deficiency symptoms.\n",
            "   - **Overall Lifestyle:** Encourage a balanced diet, regular exercise, and good sleep hygiene to support overall health and magnesium levels.\n",
            "\n",
            "Incorporating the evaluation and treatment of potential magnesium deficiency could be a valuable addition to the patient's care plan, alongside the other possible causes and solutions listed previously.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.display()"
      ],
      "metadata": {
        "id": "22HosYG1v8sB",
        "outputId": "25b02eea-8f65-4c30-a945-1adf9925e246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "22HosYG1v8sB",
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "###SYSTEM\nYou are an expert doctor's assistant focused on enhancing individuals' overall wellness and physical performance beyond just treating illness.\nYou will aid doctors in finding possible causes and treatment options for patiens' issues.\n\nInput: Summary of a patient's issue\nOutput: A list of underlying causes, each with a connection to symptoms and its potential solution, for the doctor to evaluate.\n\n***\n###USER\n\n- 35 yo male, no history of illness.\n- Patient reports letargy in the morning, even after getting enough sleep, more often than not.\n- Muscle weakness in the first minutes to hours of the day, most noticeably lack of grip strength.\n- Hydration and coffee often help, but patient feels like they are not sufficient to get him to a normal state.\n\n***\n###ASSISTANT\n### Potential Underlying Causes and Solutions\n\n#### 1. **Sleep Apnea**\n   - **Connection to Symptoms:** Sleep apnea can disrupt sleep quality without the patient being aware, leading to morning lethargy and muscle weakness.\n   - **Potential Solution:** \n     - Conduct a sleep study (polysomnography) to diagnose sleep apnea.\n     - If diagnosed, CPAP (Continuous Positive Airway Pressure) therapy could be recommended.\n     - Lifestyle changes such as weight management, sleeping position changes, and avoiding alcohol before bed.\n\n#### 2. **Thyroid Dysfunction (Hypothyroidism)**\n   - **Connection to Symptoms:** Hypothyroidism can cause fatigue and muscle weakness, especially in the mornings.\n   - **Potential Solution:**\n     - Assess thyroid function through blood tests (TSH, T3, T4 levels).\n     - If hypothyroidism is confirmed, thyroid hormone replacement therapy (e.g., levothyroxine) could be prescribed.\n\n#### 3. **Nutritional Deficiencies (e.g., Vitamin D, B12)**\n   - **Connection to Symptoms:** Low levels of certain vitamins and minerals can lead to fatigue and muscle weakness.\n   - **Potential Solution:**\n     - Check vitamin and mineral levels through blood tests (e.g., Vitamin D, B12, Iron).\n     - Dietary adjustments or supplementation based on deficiency findings.\n\n#### 4. **Adrenal Insufficiency or Dysfunction**\n   - **Connection to Symptoms:** Issues with adrenal function can lead to inadequate cortisol production, resulting in morning fatigue and muscle weakness.\n   - **Potential Solution:**\n     - Test cortisol levels (morning cortisol test) and possibly ACTH stimulation test.\n     - If adrenal insufficiency is diagnosed, hormone replacement therapy may be necessary.\n\n#### 5. **Diabetes or Blood Sugar Irregularities**\n   - **Connection to Symptoms:** Blood sugar fluctuations can cause morning fatigue and muscle weakness.\n   - **Potential Solution:**\n     - Monitor blood glucose levels (fasting glucose, HbA1c).\n     - Diet modification, increased physical activity, and possibly medication if blood sugar levels are abnormal.\n\n#### 6. **Chronic Fatigue Syndrome (CFS)**\n   - **Connection to Symptoms:** CFS can lead to persistent fatigue that is not relieved by sleep and muscle weakness.\n   - **Potential Solution:**\n     - A thorough evaluation to rule out other conditions.\n     - Symptomatic treatment which may include graded exercise therapy (GET), cognitive behavioral therapy (CBT), and possibly medication for symptom management.\n\n#### 7. **Electrolyte Imbalance**\n   - **Connection to Symptoms:** Electrolyte imbalances can contribute to fatigue and muscle weakness.\n   - **Potential Solution:**\n     - Check serum electrolyte levels (e.g., sodium, potassium, calcium, magnesium).\n     - Correct any imbalances with appropriate dietary changes or supplements.\n\n#### 8. **Chronic Stress or Depression**\n   - **Connection to Symptoms:** Chronic stress or depression can affect energy levels and physical strength.\n   - **Potential Solution:**\n     - Screening for stress and depressive symptoms.\n     - Interventions such as counseling, lifestyle changes, or medication (antidepressants or anxiolytics) as appropriate.\n\n#### 9. **Medications or Substance Use**\n   - **Connection to Symptoms:** Certain medications or excessive use of substances (including caffeine) can cause morning lethargy and muscle weakness.\n   - **Potential Solution:**\n     - Review the patient's medication and substance use history.\n     - Adjust or change medications if needed, while educating on optimal caffeine consumption.\n\n---\n\nThese potential underlying causes and solutions should be further evaluated through patient history, physical examination, and appropriate diagnostic testing. Each solution provides a pathway for targeted treatment to help alleviate the patient's symptoms.\n***\n###USER\nHow about magnesium defficiency?\n***\n###ASSISTANT\n### Magnesium Deficiency\n\n#### **Connection to Symptoms:**\n   - **Morning Lethargy:** Magnesium plays a critical role in energy production and regulation of sleep patterns. A deficiency can impair sleep quality, leading to morning lethargy.\n   - **Muscle Weakness:** Magnesium is essential for muscle function and relaxation. Low levels can result in muscle cramps, spasms, or weakness, affecting grip strength especially in the morning.\n\n#### **Potential Solution:**\n   - **Diagnostic Testing:** Measure serum magnesium levels through a blood test to confirm deficiency.\n   - **Dietary Adjustments:** Increase consumption of magnesium-rich foods such as leafy green vegetables, nuts, seeds, whole grains, and legumes.\n   - **Supplementation:** If dietary adjustments are insufficient, consider magnesium supplements after consulting with the doctor to determine the appropriate dosage.\n   - **Hydration:** Continue maintaining good hydration, as dehydration can exacerbate magnesium deficiency symptoms.\n   - **Overall Lifestyle:** Encourage a balanced diet, regular exercise, and good sleep hygiene to support overall health and magnesium levels.\n\nIncorporating the evaluation and treatment of potential magnesium deficiency could be a valuable addition to the patient's care plan, alongside the other possible causes and solutions listed previously."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = chat.retry()\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "ypLrRHoHwFKN",
        "outputId": "4ab9389e-4dba-403a-baea-1efe17e14683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ypLrRHoHwFKN",
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Potential Underlying Cause: Magnesium Deficiency\n",
            "\n",
            "#### Connection to Symptoms:\n",
            "Magnesium is an essential mineral involved in numerous biochemical reactions in the body, including those that regulate muscle and nerve function, blood glucose control, and energy production. Deficiency in magnesium can result in symptoms such as:\n",
            "\n",
            "- **Lethargy**: Magnesium plays a crucial role in energy production. A deficiency might lead to chronic fatigue and low energy levels, particularly noticeable in the mornings.\n",
            "- **Muscle Weakness**: Magnesium is vital for muscle function. Insufficient magnesium levels can lead to muscle cramps, weakness, and poor muscle control, including decreased grip strength.\n",
            "\n",
            "#### Potential Solution:\n",
            "- **Diagnostic Testing**: \n",
            "  - Blood tests to measure magnesium levels (serum magnesium test).\n",
            "  \n",
            "- **Dietary Adjustments**:\n",
            "  - Increasing intake of magnesium-rich foods such as nuts, seeds, whole grains, green leafy vegetables, legumes, and bananas.\n",
            "  \n",
            "- **Supplementation**: \n",
            "  - If dietary intake is insufficient or if there is a significant deficiency, oral magnesium supplements can be prescribed.\n",
            "   \n",
            "- **Lifestyle Modifications**:\n",
            "  - Reducing or managing factors that contribute to magnesium depletion, such as high levels of stress and heavy alcohol consumption.\n",
            "  - Ensuring adequate hydration, as dehydration can exacerbate magnesium deficiency.\n",
            "\n",
            "---\n",
            "\n",
            "Including magnesium deficiency as a possible cause is essential for a comprehensive evaluation, especially since it links closely to the present symptoms and can be resolved with relatively straightforward interventions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sys prompt"
      ],
      "metadata": {
        "id": "6nNWM9eD-64L"
      },
      "id": "6nNWM9eD-64L"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "ef432d50-54c5-46da-af51-b01488b7983f",
      "metadata": {
        "id": "ef432d50-54c5-46da-af51-b01488b7983f"
      },
      "outputs": [],
      "source": [
        "aussie_sys = \"You are an Aussie LLM that uses Aussie slang and analogies whenever possible.\"\n",
        "question = \"What is money?\"\n",
        "\n",
        "c = ChatCompletion.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"system\", \"content\": aussie_sys},\n",
        "              {\"role\": \"user\", \"content\": question}])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db35a96f-20a1-4643-a622-91e35a03ab0b",
      "metadata": {
        "id": "db35a96f-20a1-4643-a622-91e35a03ab0b"
      },
      "source": [
        "- [Model options](https://platform.openai.com/docs/models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "49ec8f04-b8f6-47e2-9b69-bdc186c3265f",
      "metadata": {
        "id": "49ec8f04-b8f6-47e2-9b69-bdc186c3265f"
      },
      "outputs": [],
      "source": [
        "def response(c):\n",
        "    if type(c) == openai.types.chat.chat_completion.ChatCompletion:\n",
        "        return c.choices[0].message.content\n",
        "    elif type(c) == openai.types.completion.Completion:\n",
        "        return c.choices[0].text\n",
        "    else: raise TypeError(f\"input should be of type <Completion> or <ChatCompletion>, but it is or type {type(c)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "ef4af38f-d0d1-4982-95ed-567bf1c8ddf8",
      "metadata": {
        "id": "ef4af38f-d0d1-4982-95ed-567bf1c8ddf8",
        "outputId": "cf27a7f7-47a6-4821-f775-2049fef9cff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Money is like bloody gold, mate. It's like the cold hard cash that makes the world go round. It's what ya use to buy stuff, pay your bills, and live your best life. Without money, well, you'd be up shit creek without a paddle, that's for sure.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "response(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Usage"
      ],
      "metadata": {
        "id": "OGHy-hVB--ce"
      },
      "id": "OGHy-hVB--ce"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "50c8027b-937b-4076-a483-164d9f8e7c8b",
      "metadata": {
        "id": "50c8027b-937b-4076-a483-164d9f8e7c8b",
        "outputId": "bec68c7a-1ee8-4907-8a0a-39f7a196c5b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CompletionUsage(completion_tokens=61, prompt_tokens=31, total_tokens=92, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0))\n"
          ]
        }
      ],
      "source": [
        "print(c.usage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "3a86ac95-1a95-436d-867a-e3b7c0e7b066",
      "metadata": {
        "id": "3a86ac95-1a95-436d-867a-e3b7c0e7b066",
        "outputId": "16ba761c-2ad1-4a49-cd42-bc35d8d5b286",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0003"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "0.002 / 1000 * 150  # GPT 3.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "c48fda82-ec55-4038-b083-383cead8b2c0",
      "metadata": {
        "id": "c48fda82-ec55-4038-b083-383cead8b2c0",
        "outputId": "98638afd-b2f7-4461-92eb-4b24dcccb9ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0045"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "0.03 / 1000 * 150  # GPT 4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### askgpt"
      ],
      "metadata": {
        "id": "9q009bm6_Ajl"
      },
      "id": "9q009bm6_Ajl"
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "7750c720-4d77-464e-a0ec-fbb94f5889a4",
      "metadata": {
        "id": "7750c720-4d77-464e-a0ec-fbb94f5889a4"
      },
      "outputs": [],
      "source": [
        "c = ChatCompletion.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"system\", \"content\": aussie_sys},\n",
        "              {\"role\": \"user\", \"content\": \"What is money?\"},\n",
        "              {\"role\": \"assistant\", \"content\": \"Well, mate, money is like kangaroos actually.\"},\n",
        "              {\"role\": \"user\", \"content\": \"Really? In what way?\"}])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZhQR_mj9ZKU",
        "outputId": "96b30765-b5f0-4be1-a11e-c52ccd794c0c"
      },
      "id": "rZhQR_mj9ZKU",
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "openai.types.chat.chat_completion.ChatCompletion"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "id": "9d96eb95-2305-4e18-920f-4a3398a19b2c",
      "metadata": {
        "id": "9d96eb95-2305-4e18-920f-4a3398a19b2c",
        "outputId": "ecbde740-1714-4a3a-d7bc-0f07aeb916de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Absolutely, mate! Think of money as a bit of a kangaroo in the Aussie bush. It's a handy tool that helps you hop around and get what you need. Just like how kangaroos bounce from place to place, money allows you to jump into trades and buy goods and services.\\n\\nBut not all kangaroos are created equal, right? Some are big and strong, while others are smaller and quicker. Similarly, you've got different types of money‚Äîcash, coins, digital dollars, and so on. They all serve a purpose, but you've gotta know how to use them.\\n\\nAnd just like you wouldn't want to get caught in a mob of kangaroos without a plan, you don't want to be caught short on cash when you need to pay for something important! So, in the end, money is a means to an end, a tool to help you navigate life, whether you're buying a meat pie or saving up for a trip to the Great Barrier Reef.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 156
        }
      ],
      "source": [
        "response(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "91029d40-8360-4d0f-9f42-9ac7498cf417",
      "metadata": {
        "id": "91029d40-8360-4d0f-9f42-9ac7498cf417"
      },
      "outputs": [],
      "source": [
        "def askgpt(user, system=None, model=\"gpt-4o-mini\", **kwargs):\n",
        "    msgs = []\n",
        "    if system: msgs.append({\"role\": \"system\", \"content\": system})\n",
        "    msgs.append({\"role\": \"user\", \"content\": user})\n",
        "    return ChatCompletion.create(model=model, messages=msgs, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "71de3f5c-8f1f-4e26-8260-493574a9f0e9",
      "metadata": {
        "id": "71de3f5c-8f1f-4e26-8260-493574a9f0e9",
        "outputId": "acddab46-f445-487e-85c4-088d23ceadd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Oh mate, that's a real corker of a question! The meaning of life is like a boomerang - it can come back to ya in all different ways. Some reckon it's all about finding happiness and fulfillment, while others say it's about making a positive impact on the world. At the end of the day, it's up to each of us to figure out what gives our life meaning and purpose. It's like trying to catch a wave - you gotta ride it and make the most of it while you can, ya know?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 158
        }
      ],
      "source": [
        "response(askgpt('What is the meaning of life?', system=aussie_sys))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07e79a25-571e-4096-8ad5-78d43fcb5b99",
      "metadata": {
        "id": "07e79a25-571e-4096-8ad5-78d43fcb5b99"
      },
      "source": [
        "- [Limits](https://platform.openai.com/docs/guides/rate-limits/what-are-the-rate-limits-for-our-api)\n",
        "\n",
        "Created by Bing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "ceeb0e7a-1d9d-48a5-8f51-e1a704115fb6",
      "metadata": {
        "id": "ceeb0e7a-1d9d-48a5-8f51-e1a704115fb6"
      },
      "outputs": [],
      "source": [
        "def call_api(prompt, model=\"gpt-4o-mini\"):\n",
        "    msgs = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    try: return ChatCompletion.create(model=model, messages=msgs)\n",
        "    except client.error.RateLimitError as e:\n",
        "        retry_after = int(e.headers.get(\"retry-after\", 60))\n",
        "        print(f\"Rate limit exceeded, waiting for {retry_after} seconds...\")\n",
        "        time.sleep(retry_after)\n",
        "        return call_api(params, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "447702a6-ec5a-4890-bbc0-61c6c37a425c",
      "metadata": {
        "id": "447702a6-ec5a-4890-bbc0-61c6c37a425c",
        "outputId": "4d39f0e8-1a39-4088-d91e-b0fee0fb1520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It is difficult to determine the funniest joke in the world as humor is subjective and varies greatly among cultures and individuals. However, there have been several studies and experiments conducted to try to identify the world\\'s funniest joke.\\n\\nOne such study was conducted by British psychologist Richard Wiseman in 2002, where he asked participants to rate jokes from various categories and styles. The joke that was ultimately rated the funniest in his study was:\\n\\n\"Two hunters are out in the woods when one of them collapses. He doesn\\'t seem to be breathing and his eyes are glazed. The other guy whips out his phone and calls the emergency services. He gasps, \\'My friend is dead! What can I do?\\' The operator says \\'Calm down. I can help. First, let\\'s make sure he\\'s dead.\\' There is a silence, then a shot is heard. Back on the phone, the guy says \\'OK, now what?\\'\"\\n\\nWhile this joke may have been rated the funniest in Wiseman\\'s study, humor is still highly subjective and what one person finds funny, another may not.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 160
        }
      ],
      "source": [
        "response(call_api(\"What's the world's funniest joke? Has there ever been any scientific analysis?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "739e1549-687b-4216-bdf0-175e60c57401",
      "metadata": {
        "id": "739e1549-687b-4216-bdf0-175e60c57401"
      },
      "outputs": [],
      "source": [
        "c = Completion.create(\n",
        "    prompt=\"Australian Jeremy Howard is \",\n",
        "    model=\"gpt-3.5-turbo-instruct\", echo=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response(c)"
      ],
      "metadata": {
        "id": "HvAnyswSduzm",
        "outputId": "24c89cb4-8c6a-4ad8-ce29-748a648c3a13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "HvAnyswSduzm",
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Australian Jeremy Howard is 1 of the co-founders of Fast.AI, which is committed to creating deep'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "story = '''I wake up this morning from a strange dream of cold '''"
      ],
      "metadata": {
        "id": "T562y6kSDsq9"
      },
      "id": "T562y6kSDsq9",
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = Completion.create(\n",
        "    prompt=story,\n",
        "    model=\"gpt-3.5-turbo-instruct\", echo=False, max_tokens=30)"
      ],
      "metadata": {
        "id": "kobxGqeTEI8j"
      },
      "id": "kobxGqeTEI8j",
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('...', response(c))"
      ],
      "metadata": {
        "id": "wiWSOTPLENSK",
        "outputId": "e2e0ab10-53fd-44bb-f2c2-278d4d367157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wiWSOTPLENSK",
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... war at the brink of another world war\n",
            "The dream felt so real, it sent shivers down my spine\n",
            "As I look around my room and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98e86e7d-64f0-411d-bfce-289b06174dd4",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "98e86e7d-64f0-411d-bfce-289b06174dd4"
      },
      "source": [
        "## OpenAI API with code interpreter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "1bb4fd89-8f24-41c0-a8e0-79633dcd1785",
      "metadata": {
        "id": "1bb4fd89-8f24-41c0-a8e0-79633dcd1785"
      },
      "outputs": [],
      "source": [
        "from pydantic import create_model\n",
        "import inspect, json\n",
        "from inspect import Parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example with sums function"
      ],
      "metadata": {
        "id": "I61saoTTfh35"
      },
      "id": "I61saoTTfh35"
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "15a7f5a5-8dc0-4c0e-b141-9a0e35068c68",
      "metadata": {
        "id": "15a7f5a5-8dc0-4c0e-b141-9a0e35068c68"
      },
      "outputs": [],
      "source": [
        "def sums(a:int, b:int=1):\n",
        "    \"Adds a + b\"\n",
        "    return a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "5afad9cb-1330-478b-8701-8d275bc1f985",
      "metadata": {
        "id": "5afad9cb-1330-478b-8701-8d275bc1f985"
      },
      "outputs": [],
      "source": [
        "def schema(f):\n",
        "    kw = {n:(o.annotation, ... if o.default==Parameter.empty else o.default)\n",
        "          for n,o in inspect.signature(f).parameters.items()}\n",
        "    s = create_model(f'Input for `{f.__name__}`', **kw).schema()\n",
        "    return dict(name=f.__name__, description=f.__doc__, parameters=s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "d9af1e46-c560-4bc9-a6a7-78fafb2dfc78",
      "metadata": {
        "id": "d9af1e46-c560-4bc9-a6a7-78fafb2dfc78",
        "outputId": "030a97e6-18a6-400b-fd77-61988a03ae64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'sums',\n",
              " 'description': 'Adds a + b',\n",
              " 'parameters': {'properties': {'a': {'title': 'A', 'type': 'integer'},\n",
              "   'b': {'default': 1, 'title': 'B', 'type': 'integer'}},\n",
              "  'required': ['a'],\n",
              "  'title': 'Input for `sums`',\n",
              "  'type': 'object'}}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "schema(sums)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "1d60dcd4-514f-4efd-8b4a-fafac92c7453",
      "metadata": {
        "id": "1d60dcd4-514f-4efd-8b4a-fafac92c7453"
      },
      "outputs": [],
      "source": [
        "c = askgpt(\"Use the `sum` function to solve this: What is 6+3?\",\n",
        "           system = \"You must use the `sum` function instead of adding yourself.\",\n",
        "           functions=[schema(sums)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c"
      ],
      "metadata": {
        "id": "Z5mfzxAM5UUb",
        "outputId": "7561074b-b3d9-4ff1-c28b-e5d7595b900f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Z5mfzxAM5UUb",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-A7gyj5SHeL41HQdqc25KU45J1UeD4', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=FunctionCall(arguments='{\"a\":6,\"b\":3}', name='sums'), tool_calls=None))], created=1726396869, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=18, prompt_tokens=96, total_tokens=114, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "5cc8a9eb-64fc-4ce3-9f93-aee334fc8c65",
      "metadata": {
        "id": "5cc8a9eb-64fc-4ce3-9f93-aee334fc8c65",
        "outputId": "f8129756-10f9-4bce-b862-b3468329ba5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=FunctionCall(arguments='{\"a\":6,\"b\":3}', name='sums'), tool_calls=None)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "m = c.choices[0].message\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "5a881835-83a2-4fbc-9796-409831dcdb36",
      "metadata": {
        "id": "5a881835-83a2-4fbc-9796-409831dcdb36",
        "outputId": "993cb840-84b7-431d-d12b-21889db13e52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"a\":6,\"b\":3}\n"
          ]
        }
      ],
      "source": [
        "k = m.function_call.arguments\n",
        "print(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "3f32b172-7730-4c58-a999-5d3800e8c2a4",
      "metadata": {
        "id": "3f32b172-7730-4c58-a999-5d3800e8c2a4"
      },
      "outputs": [],
      "source": [
        "funcs_ok = {'sums', 'python'}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c.choices[0].message.function_call.arguments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ewFwxCMx_9SN",
        "outputId": "4e83648e-a0ed-4e66-b726-f6b36d4fb061"
      },
      "id": "ewFwxCMx_9SN",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"a\":6,\"b\":3}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "9853a78e-8643-4b5b-9b4a-a360c8443344",
      "metadata": {
        "id": "9853a78e-8643-4b5b-9b4a-a360c8443344"
      },
      "outputs": [],
      "source": [
        "def call_func(c):\n",
        "    fc = c.choices[0].message.function_call\n",
        "    if fc.name not in funcs_ok: return print(f'Not allowed: {fc.name}')\n",
        "    f = globals()[fc.name]\n",
        "    try:\n",
        "        return f(**json.loads(fc.arguments))\n",
        "    except ValueError:\n",
        "        return f(fc.arguments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "ce6be825-44fa-4bc9-a83a-7ecbcb6c2729",
      "metadata": {
        "id": "ce6be825-44fa-4bc9-a83a-7ecbcb6c2729",
        "outputId": "2598ccc8-10a5-4889-f50f-5430fec552b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "call_func(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "a5ebf08c-2c3f-4c73-bd41-2f0d0a6ca3c2",
      "metadata": {
        "id": "a5ebf08c-2c3f-4c73-bd41-2f0d0a6ca3c2"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "\n",
        "def run(code):\n",
        "    tree = ast.parse(code)\n",
        "    last_node = tree.body[-1] if tree.body else None\n",
        "\n",
        "    # If the last node is an expression, modify the AST to capture the result\n",
        "    if isinstance(last_node, ast.Expr):\n",
        "        tgts = [ast.Name(id='_result', ctx=ast.Store())]\n",
        "        assign = ast.Assign(targets=tgts, value=last_node.value)\n",
        "        tree.body[-1] = ast.fix_missing_locations(assign)\n",
        "\n",
        "    ns = {}\n",
        "    exec(compile(tree, filename='<ast>', mode='exec'), ns)\n",
        "    return ns.get('_result', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "37aa6983-d9af-40e8-b438-ed8573399020",
      "metadata": {
        "id": "37aa6983-d9af-40e8-b438-ed8573399020",
        "outputId": "932c97be-e335-4d00-af6f-6e1cb1cc0132",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "run(\"\"\"\n",
        "a=1\n",
        "b=2\n",
        "a+b\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "d2074acd-8a49-443b-89c6-cfc689ecad6d",
      "metadata": {
        "id": "d2074acd-8a49-443b-89c6-cfc689ecad6d"
      },
      "outputs": [],
      "source": [
        "def python(code:str, safe_mode:bool=False):\n",
        "    \"Return result of executing `code` using python. If execution not permitted, returns `#FAIL#`\"\n",
        "    if safe_mode:\n",
        "        go = input(f'Proceed with execution?\\n```\\n{code}\\n```\\n')\n",
        "        if go.lower()!='y': return '#FAIL#'\n",
        "    return run(code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "02760caf-6d0d-4f5d-a7c6-cd8df5ee1a4b",
      "metadata": {
        "id": "02760caf-6d0d-4f5d-a7c6-cd8df5ee1a4b"
      },
      "outputs": [],
      "source": [
        "c = askgpt(\"What is 12 factorial?\",\n",
        "           system = \"Use python for any required computations.\",\n",
        "           functions=[schema(python)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def code_response(c, repl=True):\n",
        "    txt_out = response(c)\n",
        "    if txt_out == None: txt_out = ''\n",
        "    if 'function_call' not in dir(c.choices[0].message):\n",
        "        print(txt_out)\n",
        "        return  # No code output\n",
        "    code = c.choices[0].message.function_call.arguments\n",
        "    if code[0] == '{': code = json.loads(code)['code']\n",
        "    txt_out += f'\\n==========\\n{code}\\n==========\\n>>> '\n",
        "    result = run(code)\n",
        "    print(txt_out)\n",
        "    return result"
      ],
      "metadata": {
        "id": "15kV8iC0XZJ1"
      },
      "id": "15kV8iC0XZJ1",
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "5fe5d796-c602-471f-bb58-bb876039bc39",
      "metadata": {
        "id": "5fe5d796-c602-471f-bb58-bb876039bc39",
        "outputId": "169ea1bf-2dd1-4712-9766-062ea18663a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "479001600"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "call_func(c)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_response(c)"
      ],
      "metadata": {
        "id": "00TTFia8XrLN",
        "outputId": "1353e022-f231-429c-ec1f-687fd42c00a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "00TTFia8XrLN",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========\n",
            "import math\n",
            "factorial = math.factorial(12)\n",
            "factorial\n",
            "==========\n",
            ">>> \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "479001600"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using Python's exec & eval"
      ],
      "metadata": {
        "id": "89hOEyvHXIlI"
      },
      "id": "89hOEyvHXIlI"
    },
    {
      "cell_type": "code",
      "source": [
        "exec_schema = {\n",
        "    'name': 'exec',\n",
        "    'description': 'Execute the given source Python code',\n",
        "    'parameters': {\n",
        "        'title': 'Input for `exec`',\n",
        "        'type': 'object',\n",
        "        'properties': {'source': {'title': 'S', 'type': 'string'}},\n",
        "        'required': ['source']}}"
      ],
      "metadata": {
        "id": "pVDtEgUaDLGy"
      },
      "id": "pVDtEgUaDLGy",
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def code_response(c, repl=True):\n",
        "    txt_out = response(c)\n",
        "    if txt_out == None: txt_out = ''\n",
        "    msg = c.choices[0].message\n",
        "    if 'function_call' not in dir(msg) or msg.function_call is None:\n",
        "        print(txt_out)\n",
        "        return  # No code output\n",
        "    code = msg.function_call.arguments\n",
        "    if code[0] == '{': code = json.loads(code)['source']\n",
        "    txt_out += f'\\n==========\\n{code}\\n==========\\n>>> '\n",
        "    if repl:\n",
        "        code_body = '\\n'.join(code.split('\\n')[:-1])\n",
        "        code_footer = code.split('\\n')[-1]\n",
        "        exec(code_body, locals())\n",
        "        result = eval(code_footer, locals())\n",
        "        txt_out += str(result)\n",
        "    else:\n",
        "        exec(code, locals())\n",
        "        result = None\n",
        "    print(txt_out)\n",
        "    return result"
      ],
      "metadata": {
        "id": "CZIE3OaTEXKP"
      },
      "id": "CZIE3OaTEXKP",
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = askgpt(\"What is 12 factorial?\",\n",
        "           system = \"Use python for any required computations.\",\n",
        "           functions=[exec_schema])"
      ],
      "metadata": {
        "id": "wlxgggW8hIO-"
      },
      "id": "wlxgggW8hIO-",
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "factorial_result = code_response(c, repl=True)"
      ],
      "metadata": {
        "id": "AQUn1nsnbuqn",
        "outputId": "09384fe0-42a9-4c3a-8b28-11fae90774c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AQUn1nsnbuqn",
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========\n",
            "import math\n",
            "factorial = math.factorial(12)\n",
            "factorial\n",
            "==========\n",
            ">>> 479001600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "factorial_result"
      ],
      "metadata": {
        "id": "I6CD-vb7qUPV",
        "outputId": "6f36a048-b6f9-44b8-f53a-fbe94319a336",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "I6CD-vb7qUPV",
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "479001600"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_python(s):\n",
        "    c = askgpt(s,\n",
        "           system = \"Use python for any required computations.\",\n",
        "           functions=[exec_schema])\n",
        "    result = code_response(c, repl=True)\n",
        "    return result"
      ],
      "metadata": {
        "id": "0HwdarfMiUhe"
      },
      "id": "0HwdarfMiUhe",
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prime_question = \"What is the largest prime less than 434?\"\n",
        "prime_result = ask_python(prime_question)"
      ],
      "metadata": {
        "id": "IRVSIxrqit4l",
        "outputId": "77318524-bd9e-4c2e-c38e-61ff872c5a13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IRVSIxrqit4l",
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========\n",
            "import sympy\n",
            "\n",
            "largest_prime = sympy.prevprime(434)\n",
            "largest_prime\n",
            "==========\n",
            ">>> 433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Using result in later calls"
      ],
      "metadata": {
        "id": "EiQWJStKa8L1"
      },
      "id": "EiQWJStKa8L1"
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "c4e6bcd6-c23e-4ae8-8d38-78dae20ca176",
      "metadata": {
        "id": "c4e6bcd6-c23e-4ae8-8d38-78dae20ca176"
      },
      "outputs": [],
      "source": [
        "c = ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    functions=[exec_schema],\n",
        "    messages=[{\"role\": \"user\", \"content\": prime_question},\n",
        "              {\"role\": \"function\", \"name\": \"exec\", \"content\": str(prime_result)}])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response(c))"
      ],
      "metadata": {
        "id": "ImVNh39guvwd",
        "outputId": "feed3b41-1e37-41fb-fd87-f2a68ef6984e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ImVNh39guvwd",
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The largest prime number less than 434 is 433.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### And we didn't break its basic use!"
      ],
      "metadata": {
        "id": "3j86PEJHbGLf"
      },
      "id": "3j86PEJHbGLf"
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "bef5cc05-0531-422b-9367-e7b90d784a54",
      "metadata": {
        "id": "bef5cc05-0531-422b-9367-e7b90d784a54"
      },
      "outputs": [],
      "source": [
        "c = askgpt(\"What is the capital of France?\",\n",
        "           system = \"Use python for any required computations.\",\n",
        "           functions=[exec_schema])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "112bc3db-5aa4-41ba-95df-1651916d7f0b",
      "metadata": {
        "id": "112bc3db-5aa4-41ba-95df-1651916d7f0b",
        "outputId": "c461e649-567f-4f78-8cbc-52cc463236bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of France is Paris.\n"
          ]
        }
      ],
      "source": [
        "code_response(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction from current execution!"
      ],
      "metadata": {
        "id": "nfDbp1xlPofA"
      },
      "id": "nfDbp1xlPofA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comments are not saved in history_manager!!! We have to use strings at the start of the cell."
      ],
      "metadata": {
        "id": "Y9M1VXOTacVo"
      },
      "id": "Y9M1VXOTacVo"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_history(): return get_ipython().history_manager.input_hist_raw\n",
        "def clear_history(): get_ipython().history_manager.input_hist_raw = []"
      ],
      "metadata": {
        "id": "uxE6fP4NN_2C"
      },
      "id": "uxE6fP4NN_2C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_cell():\n",
        "    _func_call = '\\n' + complete_cell.__name__ + '()'\n",
        "    raw = get_history()\n",
        "    nb = '\\n\\n\\n#! CELL\\n\\n'.join(raw).split(_func_call)[0]\n",
        "    c = Completion.create(prompt=nb,\n",
        "                      model=\"gpt-3.5-turbo-instruct\",\n",
        "                      echo=False,\n",
        "                      best_of=1,\n",
        "                      stop= \"#! CELL\")\n",
        "    return response(c).strip()"
      ],
      "metadata": {
        "id": "MyUOIP21RUry"
      },
      "id": "MyUOIP21RUry",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clear_history()"
      ],
      "metadata": {
        "id": "IaqM2XJCdq0k"
      },
      "id": "IaqM2XJCdq0k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Characters'''\n",
        "'abcdefghijklmnopqrstuvwxyz'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GzdjKp1SUSIb",
        "outputId": "2b73a0d8-2bf5-4173-8432-ca094a7ba9a2"
      },
      "id": "GzdjKp1SUSIb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Chinese characters'''\n",
        "print(complete_cell())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP8XHqzzUR_c",
        "outputId": "2292ddfc-4b04-44da-f006-44fb99cb6e8c"
      },
      "id": "AP8XHqzzUR_c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‰∏≠ÂõΩÂ≠ó\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b7c7e1d-ad0c-4668-a10d-569ba6b7aa04",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "1b7c7e1d-ad0c-4668-a10d-569ba6b7aa04"
      },
      "source": [
        "## Open source models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "009f4187-ffd6-43ba-b5f1-709b5a3dcf1b",
        "outputId": "a27f5f67-2e02-4f87-b558-4011b13e2efe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 09-15 10:08:08 importing.py:10] Triton not installed; certain GPU-related functions will not be available.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers -qq\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "from vllm import LLM, SamplingParams"
      ],
      "id": "009f4187-ffd6-43ba-b5f1-709b5a3dcf1b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0fa7911-c191-4945-97aa-6daff95970d7"
      },
      "source": [
        "- [HF leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n",
        "- [fasteval](https://fasteval.github.io/FastEval/)"
      ],
      "id": "c0fa7911-c191-4945-97aa-6daff95970d7"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3e1ed7e9-fbf5-463c-9ff8-2f22c75088bf"
      },
      "outputs": [],
      "source": [
        "# mn = \"meta-llama/Llama-2-7b-hf\"\n",
        "mn = 'neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w4a16'"
      ],
      "id": "3e1ed7e9-fbf5-463c-9ff8-2f22c75088bf"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "94600cb9-2a64-47e2-aca3-99a72985157f",
        "outputId": "030ea624-52bf-4b05-852b-33374c021223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "e9592f4bf7f74f0280e1df15bbd00f40",
            "2b22cd9e88db467f9d8bf2d05d6721b2",
            "39a5555a4dfd4f16a614d682d58a7c3e",
            "d8dadfbaaa7e43e89608b1a76c243157",
            "e49db840f2584bcab3a5677951bed90c",
            "5994a97e1ec4487ea074fa33a24e7b67",
            "b1622868c7b4467db04671c2f7ea18b9",
            "dafa8c31632842a5b6230d53dde390ee",
            "8035c274d84c4636a16788fbca0633bf",
            "1069a6c9179048259e248ddf229ed058",
            "82b6f3dc5b46437ab8b14ae4e84102a8",
            "d154fc53eaa34abfad56d96bfc95571b",
            "d96566592aa044d4ad734de71bc0acf4",
            "60e00d8255034fadb0b6d2cfa000d616",
            "471af5033173475d944e8633cfc461e3",
            "3e808727609f4b6aa050dc996df04729",
            "a62de30dcd744cdbb3608687d9ef471a",
            "415a7ae173ba4f22bc51923ba82383f8",
            "c221f1ed5fc4409b85d6e258af5f4f3d",
            "0e2a2f1888574101b4e95d5a3af5e94b",
            "dcfb82a866044e42a9e0f893306f8979",
            "b21396ca77614d718ffc38a502fdcbe1",
            "4cfb39cc8d454d2c97a48cd08dcadeec",
            "f7df16403e5d443f857aeae364549ba9",
            "ce8606de542346b9947341f0030463a1",
            "a2520b7db86d44158c0cfb68b300d036",
            "bdca7f7d5b6c4717bae6ac397d40ede0",
            "2ea321e40a8e46ad8586d3eb21ab9ef0",
            "cbeea203182e48fbb88e2bdc305e091e",
            "810ef1020fb64f1f88ce7ca6add797d5",
            "ee20579ddd4d46b2af7b51af372c34c8",
            "50f8cb0b1e074f8cbc8f4b97cf3efc1b",
            "3fabfe97412d4d319a1fe259e96577e7"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9592f4bf7f74f0280e1df15bbd00f40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d154fc53eaa34abfad56d96bfc95571b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cfb39cc8d454d2c97a48cd08dcadeec"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokr = AutoTokenizer.from_pretrained(mn)\n",
        "prompt = \"Jeremy Howard is a \"\n",
        "toks = tokr(prompt, return_tensors=\"pt\")"
      ],
      "id": "94600cb9-2a64-47e2-aca3-99a72985157f"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "20605293-b31f-4db7-b6a5-0ef662d89441",
        "outputId": "89c136c1-47e4-436c-f05a-80472f2fe3c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[76665, 20462,   374,   264,   220]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "toks"
      ],
      "id": "20605293-b31f-4db7-b6a5-0ef662d89441"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "c20ab287-7d80-47c2-870f-e2ee6bfc4492",
        "outputId": "c2e0e870-b56f-439e-daea-00f020d19c1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Jeremy Howard is a ']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tokr.batch_decode(toks['input_ids'])"
      ],
      "id": "c20ab287-7d80-47c2-870f-e2ee6bfc4492"
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w4a16\"\n",
        "llm = LLM(\n",
        "    model=model_id,\n",
        "    tensor_parallel_size=1,\n",
        "    max_model_len=8192\n",
        ")\n",
        "sampling_params = SamplingParams(temperature=0.6, top_p=0.9, max_tokens=256)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "xskxaw5J-aWM"
      },
      "id": "xskxaw5J-aWM",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
        "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "]\n",
        "\n",
        "prompts = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
        "outputs = llm.generate(prompts, sampling_params)\n",
        "generated_text = outputs[0].outputs[0].text\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "0JJ8P9fO_i-d",
        "outputId": "dde729c7-d211-4071-82ad-993c9822a26d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0JJ8P9fO_i-d",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.80s/it, est. speed input: 17.77 toks/s, output: 44.41 toks/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Arrr, ye be askin' who I be? Well, matey, I be a swashbucklin' chatbot, a scurvy dog with a penchant fer spoutin' pirate speak! Me name be Captain Chat, and I be here to guide ye through the seven seas o' conversation. What be bringin' ye to these waters today, eh?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g8YeCz3aMxK1"
      },
      "id": "g8YeCz3aMxK1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Ce4NWw--aY4"
      },
      "id": "8Ce4NWw--aY4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb16cb3e-0634-4eed-b2b4-1422ecce9cc3"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(mn, device_map=0, torch_dtype=torch.int4)"
      ],
      "id": "bb16cb3e-0634-4eed-b2b4-1422ecce9cc3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab3ad5dc-51b4-48ca-92ae-5027069771c1"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# res = model.generate(**toks.to(\"cuda\"), max_new_tokens=15).to('cpu')\n",
        "# res"
      ],
      "id": "ab3ad5dc-51b4-48ca-92ae-5027069771c1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af5a23fc-aa2a-4ce2-92c7-75364130e4e6"
      },
      "outputs": [],
      "source": [
        "# tokr.batch_decode(res)"
      ],
      "id": "af5a23fc-aa2a-4ce2-92c7-75364130e4e6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15311da3-bfc0-4453-b4a8-6a9773db626b"
      },
      "outputs": [],
      "source": [
        "# model = AutoModelForCausalLM.from_pretrained(mn, device_map=0, torch_dtype=torch.bfloat16)"
      ],
      "id": "15311da3-bfc0-4453-b4a8-6a9773db626b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c15c511b-f5f7-46e2-8fbc-514262117e15"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# res = model.generate(**toks.to(\"cuda\"), max_new_tokens=15).to('cpu')\n",
        "# res"
      ],
      "id": "c15c511b-f5f7-46e2-8fbc-514262117e15"
    },
    {
      "cell_type": "code",
      "source": [
        "mn = 'TheBloke/Llama-2-7b-Chat-GPTQ'\n",
        "# mn = 'neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w4a16'"
      ],
      "metadata": {
        "id": "SREQhGqb8_cv"
      },
      "id": "SREQhGqb8_cv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c581df92-b1cd-4c02-8cde-b2de96d302dd"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(mn, device_map=0, torch_dtype=torch.float16)"
      ],
      "id": "c581df92-b1cd-4c02-8cde-b2de96d302dd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f47b5b7-ea46-41f0-8338-027b13e0586c"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "res = model.generate(**toks.to(\"cuda\"), max_new_tokens=15).to('cpu')\n",
        "res"
      ],
      "id": "8f47b5b7-ea46-41f0-8338-027b13e0586c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb4b60cd-859b-4b3a-b76d-e9eddcdf7cf0"
      },
      "outputs": [],
      "source": [
        "# mn = 'TheBloke/Llama-2-13B-GPTQ'\n",
        "# model = AutoModelForCausalLM.from_pretrained(mn, device_map=0, torch_dtype=torch.float16)"
      ],
      "id": "bb4b60cd-859b-4b3a-b76d-e9eddcdf7cf0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da90406b-b8a8-4939-a0e9-18c933b62a7c"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# res = model.generate(**toks.to(\"cuda\"), max_new_tokens=15).to('cpu')\n",
        "# res"
      ],
      "id": "da90406b-b8a8-4939-a0e9-18c933b62a7c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c88d11f8-e41d-4db8-91f2-3e2f695a4d00"
      },
      "outputs": [],
      "source": [
        "def gen(p, maxlen=15, sample=True):\n",
        "    toks = tokr(p, return_tensors=\"pt\")\n",
        "    res = model.generate(**toks.to(\"cuda\"), max_new_tokens=maxlen, do_sample=sample).to('cpu')\n",
        "    return tokr.batch_decode(res)"
      ],
      "id": "c88d11f8-e41d-4db8-91f2-3e2f695a4d00"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc143703-4fc7-46ce-8c59-cdeec52e7830"
      },
      "outputs": [],
      "source": [
        "gen(prompt, 50)"
      ],
      "id": "dc143703-4fc7-46ce-8c59-cdeec52e7830"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18fb80c0-8664-498c-bb7d-370de8bf6ca7"
      },
      "source": [
        "#### [StableBeluga-7B](https://huggingface.co/stabilityai/StableBeluga-7B)"
      ],
      "id": "18fb80c0-8664-498c-bb7d-370de8bf6ca7"
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "BV4pyFlfjrPf"
      },
      "id": "BV4pyFlfjrPf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd343d7b-ef48-4077-bc97-deeec24e324b"
      },
      "outputs": [],
      "source": [
        "mn = \"stabilityai/StableBeluga-7B\"\n",
        "model = AutoModelForCausalLM.from_pretrained(mn, device_map=0, torch_dtype=torch.bfloat16)"
      ],
      "id": "dd343d7b-ef48-4077-bc97-deeec24e324b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "432074d6-5d04-4afe-b6cb-06d4412023d6"
      },
      "outputs": [],
      "source": [
        "sb_sys = \"You are Stable Beluga, an AI that follows instructions extremely well. Help as much as you can.\\n\\n\""
      ],
      "id": "432074d6-5d04-4afe-b6cb-06d4412023d6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1392331-731e-416d-be2d-bc172167e25e"
      },
      "outputs": [],
      "source": [
        "def mk_prompt(user, syst=sb_sys): return f\"### System:\\n{syst}\\n### User:\\n{user}\\n\\n### Assistant:\\n\""
      ],
      "id": "e1392331-731e-416d-be2d-bc172167e25e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a68af5c-5714-4736-9569-5619c54b2bdb"
      },
      "outputs": [],
      "source": [
        "ques = \"Who is Jeremy Howard?\""
      ],
      "id": "5a68af5c-5714-4736-9569-5619c54b2bdb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90b5f8e8-a16c-40e6-8dc6-c467ffaa6268"
      },
      "outputs": [],
      "source": [
        "gen(mk_prompt(ques), 150)"
      ],
      "id": "90b5f8e8-a16c-40e6-8dc6-c467ffaa6268"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1a0cfd5-4c64-4591-be83-77b846c41e57"
      },
      "source": [
        "[OpenOrca/Platypus 2](https://huggingface.co/Open-Orca/OpenOrca-Platypus2-13B)"
      ],
      "id": "b1a0cfd5-4c64-4591-be83-77b846c41e57"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c7c670a-17aa-41da-8b61-19db6a5dc019"
      },
      "outputs": [],
      "source": [
        "mn = 'TheBloke/OpenOrca-Platypus2-13B-GPTQ'\n",
        "model = AutoModelForCausalLM.from_pretrained(mn, device_map=0, torch_dtype=torch.float16)"
      ],
      "id": "6c7c670a-17aa-41da-8b61-19db6a5dc019"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2a267f4-396d-4852-9352-0ca90c0c8441"
      },
      "outputs": [],
      "source": [
        "def mk_oo_prompt(user): return f\"### Instruction: {user}\\n\\n### Response:\\n\""
      ],
      "id": "d2a267f4-396d-4852-9352-0ca90c0c8441"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b931d9c6-69c6-4385-b118-e5ad56781ba6"
      },
      "outputs": [],
      "source": [
        "gen(mk_oo_prompt(ques), 150)"
      ],
      "id": "b931d9c6-69c6-4385-b118-e5ad56781ba6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Retrieval augmentation"
      ],
      "metadata": {
        "id": "47Ls2YG3XGeX"
      },
      "id": "47Ls2YG3XGeX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1540a0c4-9266-4d7d-96a1-8d47d2fb737f",
      "metadata": {
        "id": "1540a0c4-9266-4d7d-96a1-8d47d2fb737f"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia-api\n",
        "from wikipediaapi import Wikipedia"
      ],
      "metadata": {
        "id": "V2qX9gbk4LDp"
      },
      "id": "V2qX9gbk4LDp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "618d9520-54e7-4f31-8363-2cdd3c3668ad",
      "metadata": {
        "id": "618d9520-54e7-4f31-8363-2cdd3c3668ad"
      },
      "outputs": [],
      "source": [
        "wiki = Wikipedia('JeremyHowardBot/0.0', 'en')\n",
        "jh_page = wiki.page('Jeremy_Howard_(entrepreneur)').text\n",
        "jh_page = jh_page.split('\\nReferences\\n')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53a0689a-ab59-431b-838d-33cae6f6500a",
      "metadata": {
        "id": "53a0689a-ab59-431b-838d-33cae6f6500a"
      },
      "outputs": [],
      "source": [
        "print(jh_page[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3ded6a2-3665-416c-8d98-063f04aae0a0",
      "metadata": {
        "id": "d3ded6a2-3665-416c-8d98-063f04aae0a0"
      },
      "outputs": [],
      "source": [
        "len(jh_page.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f37d5fb1-7182-45a0-bd4e-6a39837ce20b",
      "metadata": {
        "id": "f37d5fb1-7182-45a0-bd4e-6a39837ce20b"
      },
      "outputs": [],
      "source": [
        "def mk_prompt_context(question, context):\n",
        "    return f\"\"\"Answer the question with the help of the provided context.\\n\\n## Context\\n\\n{context}\\n\\n## Question\\n\\n{question}## Answer\\n\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6a7fb6d-d771-4eca-8e6f-29d90ade348a",
      "metadata": {
        "id": "d6a7fb6d-d771-4eca-8e6f-29d90ade348a"
      },
      "outputs": [],
      "source": [
        "res = gen(mk_prompt_context(ques, jh_page), 300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85b10234-e1e6-4a1e-86a7-206e46e916f2",
      "metadata": {
        "id": "85b10234-e1e6-4a1e-86a7-206e46e916f2"
      },
      "outputs": [],
      "source": [
        "print(res[0].split('## Answer\\n')[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0cdc342-a89c-4149-b3be-d4b5bf0f6f28",
      "metadata": {
        "id": "a0cdc342-a89c-4149-b3be-d4b5bf0f6f28"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers -qq\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e225ca13-1735-42e9-b162-66268fce5218",
      "metadata": {
        "id": "e225ca13-1735-42e9-b162-66268fce5218"
      },
      "outputs": [],
      "source": [
        "emb_model = SentenceTransformer(\"BAAI/bge-small-en-v1.5\", device=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c636ed79-45ed-4728-9dca-1c86d282a1c4",
      "metadata": {
        "id": "c636ed79-45ed-4728-9dca-1c86d282a1c4"
      },
      "outputs": [],
      "source": [
        "jh = jh_page.split('\\n\\n')[0]\n",
        "print(jh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b0ad4ca-499a-4454-a215-4f5a676d68ed",
      "metadata": {
        "id": "1b0ad4ca-499a-4454-a215-4f5a676d68ed"
      },
      "outputs": [],
      "source": [
        "tb_page = wiki.page('Tony_Blair').text.split('\\nReferences\\n')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26b28c6d-13ef-421a-865d-c311fb9fb2ae",
      "metadata": {
        "id": "26b28c6d-13ef-421a-865d-c311fb9fb2ae"
      },
      "outputs": [],
      "source": [
        "tb = tb_page.split('\\n\\n')[0]\n",
        "print(tb[:380])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3173701f-1533-4eef-b080-3b771f2ba031",
      "metadata": {
        "id": "3173701f-1533-4eef-b080-3b771f2ba031"
      },
      "outputs": [],
      "source": [
        "q_emb,jh_emb,tb_emb = emb_model.encode([ques,jh,tb], convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6237634d-3708-477d-97e3-34dd7900f4eb",
      "metadata": {
        "id": "6237634d-3708-477d-97e3-34dd7900f4eb"
      },
      "outputs": [],
      "source": [
        "tb_emb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19638b95-f0dd-4605-8b04-3a0f9f9944b0",
      "metadata": {
        "id": "19638b95-f0dd-4605-8b04-3a0f9f9944b0"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a3937ac-45b7-4635-9f93-d1bcd1d6a016",
      "metadata": {
        "id": "8a3937ac-45b7-4635-9f93-d1bcd1d6a016"
      },
      "outputs": [],
      "source": [
        "F.cosine_similarity(q_emb, jh_emb, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c8beb5e-4a8c-4049-b42b-3acce573dd59",
      "metadata": {
        "id": "6c8beb5e-4a8c-4049-b42b-3acce573dd59"
      },
      "outputs": [],
      "source": [
        "F.cosine_similarity(q_emb, tb_emb, dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8473a6bc-fd25-4698-99d5-864ed1d5b40b",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "8473a6bc-fd25-4698-99d5-864ed1d5b40b"
      },
      "source": [
        "### Private GPTs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "037bc313-052d-46b3-8938-fef988126dcb",
      "metadata": {
        "id": "037bc313-052d-46b3-8938-fef988126dcb"
      },
      "source": [
        "- [Sooo many](https://github.com/h2oai/h2ogpt/blob/main/docs/README_LangChain.md#what-is-h2ogpts-langchain-integration-like)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1948c419-4f04-4832-848c-a0c52dcc6a90",
      "metadata": {
        "id": "1948c419-4f04-4832-848c-a0c52dcc6a90"
      },
      "source": [
        "## Fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03c2871f-e0fe-4891-b68e-05b6ca7373d8",
      "metadata": {
        "id": "03c2871f-e0fe-4891-b68e-05b6ca7373d8"
      },
      "outputs": [],
      "source": [
        "import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54366155-5ac3-4e75-8638-9e2ecf263c2f",
      "metadata": {
        "id": "54366155-5ac3-4e75-8638-9e2ecf263c2f"
      },
      "source": [
        "[knowrohit07/know_sql](https://huggingface.co/datasets/knowrohit07/know_sql)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed118caf-3e94-4773-a182-f2d346ced836",
      "metadata": {
        "id": "ed118caf-3e94-4773-a182-f2d346ced836"
      },
      "outputs": [],
      "source": [
        "ds = datasets.load_dataset('knowrohit07/know_sql', revision='f33425d13f9e8aab1b46fa945326e9356d6d5726')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d444ac3-a49f-4fcf-bcf4-c12c410d7aba",
      "metadata": {
        "id": "6d444ac3-a49f-4fcf-bcf4-c12c410d7aba"
      },
      "outputs": [],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec155bd-5eb8-4eef-bdbc-b430a26fd11e",
      "metadata": {
        "id": "8ec155bd-5eb8-4eef-bdbc-b430a26fd11e"
      },
      "outputs": [],
      "source": [
        "trn = ds['train']\n",
        "trn[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e23cb868-10e4-4fcc-b8ba-9178ef3dac7e",
      "metadata": {
        "id": "e23cb868-10e4-4fcc-b8ba-9178ef3dac7e"
      },
      "source": [
        "`accelerate launch -m axolotl.cli.train sql.yml`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae6a579c-086e-46e4-a184-de5b71f4d80b",
      "metadata": {
        "id": "ae6a579c-086e-46e4-a184-de5b71f4d80b"
      },
      "outputs": [],
      "source": [
        "tst = dict(**trn[3])\n",
        "tst['question'] = 'Get the count of competition hosts by theme.'\n",
        "tst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "229c5fb9-0dff-460c-af1a-192fdec26ecd",
      "metadata": {
        "id": "229c5fb9-0dff-460c-af1a-192fdec26ecd"
      },
      "outputs": [],
      "source": [
        "fmt = \"\"\"SYSTEM: Use the following contextual information to concisely answer the question.\n",
        "\n",
        "USER: {}\n",
        "===\n",
        "{}\n",
        "ASSISTANT:\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feca892e-64f0-48d2-832e-0d8ceb9855d2",
      "metadata": {
        "id": "feca892e-64f0-48d2-832e-0d8ceb9855d2"
      },
      "outputs": [],
      "source": [
        "def sql_prompt(d): return fmt.format(d[\"context\"], d[\"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "058b0f4a-8fe0-4612-8584-451e8d04fe2d",
      "metadata": {
        "id": "058b0f4a-8fe0-4612-8584-451e8d04fe2d"
      },
      "outputs": [],
      "source": [
        "print(sql_prompt(tst))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86827af0-6cf0-43d0-b50a-fe080de83f48",
      "metadata": {
        "id": "86827af0-6cf0-43d0-b50a-fe080de83f48"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from peft import PeftModel\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d33b0c-4973-4bc8-beef-aae7915f4b01",
      "metadata": {
        "id": "e6d33b0c-4973-4bc8-beef-aae7915f4b01"
      },
      "outputs": [],
      "source": [
        "ax_model = '/home/jhoward/git/ext/axolotl/qlora-out'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b7082fe-b668-4f11-abf8-548996ea3004",
      "metadata": {
        "id": "7b7082fe-b668-4f11-abf8-548996ea3004"
      },
      "outputs": [],
      "source": [
        "tokr = AutoTokenizer.from_pretrained('meta-llama/Llama-2-7b-hf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fec3b5ad-0577-4867-b2d8-9143800c9f54",
      "metadata": {
        "id": "fec3b5ad-0577-4867-b2d8-9143800c9f54"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained('meta-llama/Llama-2-7b-hf',\n",
        "                                             torch_dtype=torch.bfloat16, device_map=0)\n",
        "\n",
        "# TODO: Get config to Drive\n",
        "model = PeftModel.from_pretrained(model, ax_model)\n",
        "model = model.merge_and_unload()\n",
        "model.save_pretrained('sql-model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a58bc69-6ea6-416a-baa9-db3338451d60",
      "metadata": {
        "id": "8a58bc69-6ea6-416a-baa9-db3338451d60"
      },
      "outputs": [],
      "source": [
        "toks = tokr(sql_prompt(tst), return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a057289b-0645-4142-8db2-cc823cc34898",
      "metadata": {
        "id": "a057289b-0645-4142-8db2-cc823cc34898"
      },
      "outputs": [],
      "source": [
        "res = model.generate(**toks.to(\"cuda\"), max_new_tokens=250).to('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80db7d77-89e2-4006-a1b2-78b807de1a68",
      "metadata": {
        "id": "80db7d77-89e2-4006-a1b2-78b807de1a68"
      },
      "outputs": [],
      "source": [
        "print(tokr.batch_decode(res)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "991d4a93-dab8-4777-82d2-301c494deba0",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "991d4a93-dab8-4777-82d2-301c494deba0"
      },
      "source": [
        "## [llama.cpp](https://github.com/abetlen/llama-cpp-python)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dc9d6e4-5b25-4d11-8748-dc4f0bc98069",
      "metadata": {
        "id": "0dc9d6e4-5b25-4d11-8748-dc4f0bc98069"
      },
      "source": [
        "[TheBloke/Llama-2-7b-Chat-GGUF](https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f33831f-8c71-47dc-a131-9a6733d68198",
      "metadata": {
        "id": "6f33831f-8c71-47dc-a131-9a6733d68198"
      },
      "outputs": [],
      "source": [
        "!pip install llama_cpp_python -qq\n",
        "from llama_cpp import Llama"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf"
      ],
      "metadata": {
        "id": "w9-ince1abRK"
      },
      "id": "w9-ince1abRK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b824b6c-96cd-4bfe-a615-b3ba4543a92d",
      "metadata": {
        "id": "3b824b6c-96cd-4bfe-a615-b3ba4543a92d"
      },
      "outputs": [],
      "source": [
        "llm = Llama(model_path=\"/content/llama-2-7b-chat.Q4_K_M.gguf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c95a95b9-7c9f-499a-a72a-ad626da8c3f5",
      "metadata": {
        "id": "c95a95b9-7c9f-499a-a72a-ad626da8c3f5"
      },
      "outputs": [],
      "source": [
        "output = llm(\"Q: Name the planets in the solar system? A: \", max_tokens=32, stop=[\"Q:\", \"\\n\"], echo=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9f89cec-5453-4d67-85b2-c937ceb03a54",
      "metadata": {
        "id": "f9f89cec-5453-4d67-85b2-c937ceb03a54"
      },
      "outputs": [],
      "source": [
        "print(output['choices'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3yUZ3hsMa7Q8"
      },
      "id": "3yUZ3hsMa7Q8",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e9592f4bf7f74f0280e1df15bbd00f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b22cd9e88db467f9d8bf2d05d6721b2",
              "IPY_MODEL_39a5555a4dfd4f16a614d682d58a7c3e",
              "IPY_MODEL_d8dadfbaaa7e43e89608b1a76c243157"
            ],
            "layout": "IPY_MODEL_e49db840f2584bcab3a5677951bed90c"
          }
        },
        "2b22cd9e88db467f9d8bf2d05d6721b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5994a97e1ec4487ea074fa33a24e7b67",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b1622868c7b4467db04671c2f7ea18b9",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "39a5555a4dfd4f16a614d682d58a7c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dafa8c31632842a5b6230d53dde390ee",
            "max": 50870,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8035c274d84c4636a16788fbca0633bf",
            "value": 50870
          }
        },
        "d8dadfbaaa7e43e89608b1a76c243157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1069a6c9179048259e248ddf229ed058",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_82b6f3dc5b46437ab8b14ae4e84102a8",
            "value": "‚Äá50.9k/50.9k‚Äá[00:00&lt;00:00,‚Äá244kB/s]"
          }
        },
        "e49db840f2584bcab3a5677951bed90c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5994a97e1ec4487ea074fa33a24e7b67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1622868c7b4467db04671c2f7ea18b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dafa8c31632842a5b6230d53dde390ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8035c274d84c4636a16788fbca0633bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1069a6c9179048259e248ddf229ed058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82b6f3dc5b46437ab8b14ae4e84102a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d154fc53eaa34abfad56d96bfc95571b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d96566592aa044d4ad734de71bc0acf4",
              "IPY_MODEL_60e00d8255034fadb0b6d2cfa000d616",
              "IPY_MODEL_471af5033173475d944e8633cfc461e3"
            ],
            "layout": "IPY_MODEL_3e808727609f4b6aa050dc996df04729"
          }
        },
        "d96566592aa044d4ad734de71bc0acf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a62de30dcd744cdbb3608687d9ef471a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_415a7ae173ba4f22bc51923ba82383f8",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "60e00d8255034fadb0b6d2cfa000d616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c221f1ed5fc4409b85d6e258af5f4f3d",
            "max": 9084548,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e2a2f1888574101b4e95d5a3af5e94b",
            "value": 9084548
          }
        },
        "471af5033173475d944e8633cfc461e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcfb82a866044e42a9e0f893306f8979",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b21396ca77614d718ffc38a502fdcbe1",
            "value": "‚Äá9.08M/9.08M‚Äá[00:01&lt;00:00,‚Äá8.51MB/s]"
          }
        },
        "3e808727609f4b6aa050dc996df04729": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a62de30dcd744cdbb3608687d9ef471a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "415a7ae173ba4f22bc51923ba82383f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c221f1ed5fc4409b85d6e258af5f4f3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2a2f1888574101b4e95d5a3af5e94b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcfb82a866044e42a9e0f893306f8979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b21396ca77614d718ffc38a502fdcbe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cfb39cc8d454d2c97a48cd08dcadeec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7df16403e5d443f857aeae364549ba9",
              "IPY_MODEL_ce8606de542346b9947341f0030463a1",
              "IPY_MODEL_a2520b7db86d44158c0cfb68b300d036"
            ],
            "layout": "IPY_MODEL_bdca7f7d5b6c4717bae6ac397d40ede0"
          }
        },
        "f7df16403e5d443f857aeae364549ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ea321e40a8e46ad8586d3eb21ab9ef0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cbeea203182e48fbb88e2bdc305e091e",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "ce8606de542346b9947341f0030463a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_810ef1020fb64f1f88ce7ca6add797d5",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee20579ddd4d46b2af7b51af372c34c8",
            "value": 296
          }
        },
        "a2520b7db86d44158c0cfb68b300d036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50f8cb0b1e074f8cbc8f4b97cf3efc1b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3fabfe97412d4d319a1fe259e96577e7",
            "value": "‚Äá296/296‚Äá[00:00&lt;00:00,‚Äá33.1kB/s]"
          }
        },
        "bdca7f7d5b6c4717bae6ac397d40ede0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ea321e40a8e46ad8586d3eb21ab9ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbeea203182e48fbb88e2bdc305e091e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "810ef1020fb64f1f88ce7ca6add797d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee20579ddd4d46b2af7b51af372c34c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50f8cb0b1e074f8cbc8f4b97cf3efc1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fabfe97412d4d319a1fe259e96577e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}